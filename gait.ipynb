{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d02eb31a",
   "metadata": {},
   "source": [
    "## Things to reconsider \n",
    "1. data split \n",
    "2. minimum nuber of sequence \n",
    "3. sequence length\n",
    "4. hight,width \n",
    "5. mixed precision \n",
    "6. gpu \n",
    "7. callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "32ab2709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Get helper functions file\\nimport os\\n\\nhelper_url = \"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\"\\nhelper_path = \"helper_functions.py\"\\n\\nif not os.path.exists(helper_path):\\n    import urllib.request\\n    print(f\"[INFO] Downloading \\'{helper_path}\\'...\")\\n    urllib.request.urlretrieve(helper_url, helper_path)\\n    print(f\"[INFO] Downloaded \\'{helper_path}\\'.\")\\nelse:\\n    print(f\"[INFO] \\'{helper_path}\\' already exists, skipping download.\")'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Get helper functions file\n",
    "import os\n",
    "\n",
    "helper_url = \"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\"\n",
    "helper_path = \"helper_functions.py\"\n",
    "\n",
    "if not os.path.exists(helper_path):\n",
    "    import urllib.request\n",
    "    print(f\"[INFO] Downloading '{helper_path}'...\")\n",
    "    urllib.request.urlretrieve(helper_url, helper_path)\n",
    "    print(f\"[INFO] Downloaded '{helper_path}'.\")\n",
    "else:\n",
    "    print(f\"[INFO] '{helper_path}' already exists, skipping download.\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1129e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_casia_b_data(dataset_path):\n",
    "    \"\"\"\n",
    "    Load CASIA-B dataset and split into training and testing lists using the\n",
    "    standard protocol:\n",
    "      - Training: Subjects 001-074\n",
    "      - Testing:  Subjects 075-124\n",
    "\n",
    "    Returns:\n",
    "      train_data: List of dicts for each training sequence\n",
    "      test_data:  List of dicts for each testing sequence\n",
    "    \"\"\"\n",
    "    # Define subjects\n",
    "    train_subjects = [f\"{i:03d}\" for i in range(1, 85)]   \n",
    "    test_subjects  = [f\"{i:03d}\" for i in range(85, 125)] \n",
    "\n",
    "    # Define conditions and sequences\n",
    "    conditions = {\n",
    "        'nm': ['nm-01','nm-02','nm-03','nm-04','nm-05','nm-06'],\n",
    "        'bg': ['bg-01','bg-02'],\n",
    "        'cl': ['cl-01','cl-02']\n",
    "    }\n",
    "    # Define views (0° to 180° in 18° steps)\n",
    "    views = [\"090\"]\n",
    "\n",
    "    # Helper to gather data entries\n",
    "    def gather_entries(subject_list):\n",
    "        entries = []\n",
    "        for subject in subject_list:\n",
    "            subj_path = os.path.join(dataset_path, subject)\n",
    "            if not os.path.isdir(subj_path):\n",
    "                continue\n",
    "            for cond, seqs in conditions.items():\n",
    "                for seq in seqs:\n",
    "                    seq_path = os.path.join(subj_path, seq)\n",
    "                    if not os.path.isdir(seq_path):\n",
    "                        continue\n",
    "                    for view in views:\n",
    "                        view_path = os.path.join(seq_path, view)\n",
    "                        if not os.path.isdir(view_path):\n",
    "                            continue\n",
    "                        # Count PNG frames\n",
    "                        frames = [f for f in os.listdir(view_path) if f.endswith('.png')]\n",
    "                        entries.append({\n",
    "                            'subject': subject,\n",
    "                            'condition': cond,\n",
    "                            'sequence': seq,\n",
    "                            'view': view,\n",
    "                            'path': view_path,\n",
    "                            'num_frames': len(frames)\n",
    "                        })\n",
    "        return entries\n",
    "\n",
    "    # Gather train and test data\n",
    "    train_data = gather_entries(train_subjects)\n",
    "    test_data  = gather_entries(test_subjects)\n",
    "\n",
    "    print(f\"Loaded {len(train_data)} training sequences from {len(train_subjects)} subjects\")\n",
    "    print(f\"Loaded {len(test_data)} testing sequences from {len(test_subjects)} subjects\")\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "# Example usage:\n",
    "# train_data, test_data = load_casia_b_data('/path/to/CASIA-B-extracted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32c0f9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 training sequences from 84 subjects\n",
      "Loaded 0 testing sequences from 40 subjects\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = load_casia_b_data(r'D:\\vit study\\Machine Learning\\CASIA - B\\CASIA - B\\GaitDatasetB-silh\\GaitDatasetB-silh\\GaitDatasetB-silh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "936c1bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': '001',\n",
       " 'condition': 'nm',\n",
       " 'sequence': 'nm-01',\n",
       " 'view': '000',\n",
       " 'path': 'D:\\\\vit study\\\\Machine Learning\\\\CASIA - B\\\\CASIA - B\\\\GaitDatasetB-silh\\\\GaitDatasetB-silh\\\\GaitDatasetB-silh\\\\001\\\\nm-01\\\\000',\n",
       " 'num_frames': 96}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f7a56470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sequences per condition:\n",
      "condition\n",
      "nm    5544\n",
      "bg    1848\n",
      "cl    1848\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Test sequences per condition:\n",
      "condition\n",
      "nm    2640\n",
      "bg     880\n",
      "cl     880\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert to DataFrame for easy analysis\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df  = pd.DataFrame(test_data)\n",
    "\n",
    "# 1. Number of sequences per condition\n",
    "print(\"Train sequences per condition:\")\n",
    "print(train_df['condition'].value_counts(), \"\\n\")\n",
    "\n",
    "print(\"Test sequences per condition:\")\n",
    "print(test_df['condition'].value_counts(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "801aa941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train sequences and mean lengths by condition & view:\n",
      "           count                                                  \n",
      "view        000  018  036  054  072  090  108  126  144  162  180\n",
      "condition                                                        \n",
      "bg          168  168  168  168  168  168  168  168  168  168  168\n",
      "cl          168  168  168  168  168  168  168  168  168  168  168\n",
      "nm          504  504  504  504  504  504  504  504  504  504  504\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stats = train_df.groupby(['condition','view'])['num_frames'].agg(['count']).unstack(fill_value=0)\n",
    "print(\"\\nTrain sequences and mean lengths by condition & view:\\n\", stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec00da8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['001', '002', '003', '004', '005', '006', '007', '008', '009',\n",
       "       '010', '011', '012', '013', '014', '015', '016', '017', '018',\n",
       "       '019', '020', '021', '022', '023', '024', '025', '026', '027',\n",
       "       '028', '029', '030', '031', '032', '033', '034', '035', '036',\n",
       "       '037', '038', '039', '040', '041', '042', '043', '044', '045',\n",
       "       '046', '047', '048', '049', '050', '051', '052', '053', '054',\n",
       "       '055', '056', '057', '058', '059', '060', '061', '062', '063',\n",
       "       '064', '065', '066', '067', '068', '069', '070', '071', '072',\n",
       "       '073', '074', '075', '076', '077', '078', '079', '080', '081',\n",
       "       '082', '083', '084'], dtype=object)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes=train_df[\"subject\"].unique()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7ea6fea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nm-01', 'nm-02', 'nm-03', 'nm-04', 'nm-05', 'nm-06', 'bg-01',\n",
       "       'bg-02', 'cl-01', 'cl-02'], dtype=object)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"sequence\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "14907b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 204\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(os.listdir(ent['path'])) for ent in train_data]\n",
    "print(min(lengths), max(lengths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e133833f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty training sequences: 63\n",
      "Subject 005, Condition nm, Sequence nm-01, View 000\n",
      "Subject 005, Condition nm, Sequence nm-02, View 000\n",
      "Subject 005, Condition nm, Sequence nm-03, View 000\n",
      "Subject 005, Condition nm, Sequence nm-03, View 090\n",
      "Subject 005, Condition nm, Sequence nm-04, View 000\n",
      "Subject 005, Condition nm, Sequence nm-04, View 090\n",
      "Subject 005, Condition nm, Sequence nm-05, View 000\n",
      "Subject 005, Condition nm, Sequence nm-06, View 000\n",
      "Subject 005, Condition nm, Sequence nm-06, View 090\n",
      "Subject 005, Condition bg, Sequence bg-01, View 000\n",
      "Subject 005, Condition bg, Sequence bg-01, View 090\n",
      "Subject 005, Condition bg, Sequence bg-02, View 000\n",
      "Subject 005, Condition bg, Sequence bg-02, View 072\n",
      "Subject 005, Condition bg, Sequence bg-02, View 090\n",
      "Subject 005, Condition cl, Sequence cl-01, View 000\n",
      "Subject 005, Condition cl, Sequence cl-02, View 000\n",
      "Subject 026, Condition cl, Sequence cl-02, View 162\n",
      "Subject 037, Condition bg, Sequence bg-01, View 018\n",
      "Subject 037, Condition bg, Sequence bg-01, View 126\n",
      "Subject 037, Condition bg, Sequence bg-01, View 144\n",
      "Subject 037, Condition bg, Sequence bg-01, View 162\n",
      "Subject 037, Condition bg, Sequence bg-01, View 180\n",
      "Subject 037, Condition bg, Sequence bg-02, View 018\n",
      "Subject 037, Condition bg, Sequence bg-02, View 036\n",
      "Subject 037, Condition bg, Sequence bg-02, View 054\n",
      "Subject 037, Condition bg, Sequence bg-02, View 126\n",
      "Subject 037, Condition bg, Sequence bg-02, View 162\n",
      "Subject 048, Condition bg, Sequence bg-02, View 018\n",
      "Subject 048, Condition cl, Sequence cl-01, View 018\n",
      "Subject 048, Condition cl, Sequence cl-01, View 036\n",
      "Subject 048, Condition cl, Sequence cl-01, View 162\n",
      "Subject 048, Condition cl, Sequence cl-02, View 018\n",
      "Subject 048, Condition cl, Sequence cl-02, View 036\n",
      "Subject 048, Condition cl, Sequence cl-02, View 054\n",
      "Subject 048, Condition cl, Sequence cl-02, View 126\n",
      "Subject 048, Condition cl, Sequence cl-02, View 144\n",
      "Subject 048, Condition cl, Sequence cl-02, View 162\n",
      "Subject 068, Condition nm, Sequence nm-01, View 018\n",
      "Subject 068, Condition nm, Sequence nm-01, View 036\n",
      "Subject 068, Condition nm, Sequence nm-01, View 054\n",
      "Subject 068, Condition nm, Sequence nm-01, View 126\n",
      "Subject 068, Condition nm, Sequence nm-01, View 144\n",
      "Subject 068, Condition nm, Sequence nm-01, View 162\n",
      "Subject 068, Condition nm, Sequence nm-02, View 036\n",
      "Subject 068, Condition nm, Sequence nm-02, View 054\n",
      "Subject 068, Condition nm, Sequence nm-02, View 126\n",
      "Subject 068, Condition nm, Sequence nm-02, View 162\n",
      "Subject 068, Condition nm, Sequence nm-03, View 000\n",
      "Subject 068, Condition nm, Sequence nm-03, View 036\n",
      "Subject 068, Condition nm, Sequence nm-03, View 054\n",
      "Subject 068, Condition nm, Sequence nm-03, View 126\n",
      "Subject 068, Condition nm, Sequence nm-03, View 144\n",
      "Subject 068, Condition nm, Sequence nm-03, View 180\n",
      "Subject 068, Condition nm, Sequence nm-04, View 000\n",
      "Subject 068, Condition nm, Sequence nm-04, View 018\n",
      "Subject 068, Condition nm, Sequence nm-04, View 054\n",
      "Subject 068, Condition nm, Sequence nm-04, View 126\n",
      "Subject 068, Condition nm, Sequence nm-04, View 144\n",
      "Subject 079, Condition bg, Sequence bg-01, View 054\n",
      "Subject 079, Condition bg, Sequence bg-02, View 018\n",
      "Subject 079, Condition bg, Sequence bg-02, View 036\n",
      "Subject 079, Condition bg, Sequence bg-02, View 054\n",
      "Subject 079, Condition bg, Sequence bg-02, View 162\n",
      "\n",
      "Empty testing sequences: 23\n",
      "Subject 088, Condition nm, Sequence nm-02, View 018\n",
      "Subject 088, Condition nm, Sequence nm-02, View 036\n",
      "Subject 088, Condition nm, Sequence nm-02, View 054\n",
      "Subject 088, Condition nm, Sequence nm-03, View 018\n",
      "Subject 088, Condition nm, Sequence nm-03, View 036\n",
      "Subject 088, Condition nm, Sequence nm-03, View 054\n",
      "Subject 088, Condition nm, Sequence nm-03, View 126\n",
      "Subject 088, Condition nm, Sequence nm-03, View 162\n",
      "Subject 088, Condition nm, Sequence nm-03, View 180\n",
      "Subject 088, Condition nm, Sequence nm-04, View 018\n",
      "Subject 088, Condition nm, Sequence nm-04, View 036\n",
      "Subject 088, Condition nm, Sequence nm-04, View 054\n",
      "Subject 088, Condition nm, Sequence nm-04, View 126\n",
      "Subject 088, Condition nm, Sequence nm-04, View 144\n",
      "Subject 088, Condition nm, Sequence nm-04, View 162\n",
      "Subject 088, Condition nm, Sequence nm-04, View 180\n",
      "Subject 096, Condition nm, Sequence nm-03, View 018\n",
      "Subject 096, Condition nm, Sequence nm-03, View 054\n",
      "Subject 109, Condition nm, Sequence nm-01, View 126\n",
      "Subject 109, Condition nm, Sequence nm-01, View 144\n",
      "Subject 109, Condition nm, Sequence nm-01, View 162\n",
      "Subject 109, Condition nm, Sequence nm-01, View 180\n",
      "Subject 109, Condition nm, Sequence nm-04, View 126\n"
     ]
    }
   ],
   "source": [
    "# List entries with zero frames\n",
    "empty_train = [e for e in train_data if e['num_frames'] <= 10]\n",
    "empty_test  = [e for e in test_data  if e['num_frames'] <= 10]\n",
    "\n",
    "print(f\"Empty training sequences: {len(empty_train)}\")\n",
    "for e in empty_train:\n",
    "    print(f\"Subject {e['subject']}, Condition {e['condition']}, Sequence {e['sequence']}, View {e['view']}\")\n",
    "\n",
    "print(f\"\\nEmpty testing sequences: {len(empty_test)}\")\n",
    "for e in empty_test:\n",
    "    print(f\"Subject {e['subject']}, Condition {e['condition']}, Sequence {e['sequence']}, View {e['view']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3343f7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sequences after filtering: 9178\n",
      "Testing sequences after filtering: 4378\n"
     ]
    }
   ],
   "source": [
    "MIN_SEQ_LEN = 10\n",
    "\n",
    "# Filter training data\n",
    "filtered_train = []\n",
    "for e in train_data:\n",
    "    if e['num_frames'] >= MIN_SEQ_LEN:\n",
    "        filtered_train.append(e)\n",
    "\n",
    "# Filter testing data\n",
    "filtered_test = []\n",
    "for e in test_data:\n",
    "    if e['num_frames'] >= MIN_SEQ_LEN:\n",
    "        filtered_test.append(e)\n",
    "\n",
    "# Update the original lists\n",
    "train_data = filtered_train\n",
    "test_data = filtered_test\n",
    "\n",
    "print(f\"Training sequences after filtering: {len(train_data)}\")\n",
    "print(f\"Testing sequences after filtering: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d45d47c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2035\n",
      "Subject: 019, Condition: bg, Sequence: bg-01, View: 072, Number of frames: 51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28fb1254070>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "rand_num = random.choice(range(len(train_data)))\n",
    "print(rand_num)\n",
    "sample=train_data[rand_num]\n",
    "sample_path=sample[\"path\"]\n",
    "sample_frames=os.listdir(sample_path)\n",
    "image=plt.imread(os.path.join(sample_path,random.choice(sample_frames)))\n",
    "print(f\"Subject: {sample['subject']}, Condition: {sample['condition']}, Sequence: {sample['sequence']}, View: {sample['view']}, Number of frames: {sample['num_frames']}\")  \n",
    "plt.imshow(image, cmap='prism_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "eec7e408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Pick the first training sequence\n",
    "rand_num = random.choice(range(len(train_data)))\n",
    "sample = train_data[rand_num]\n",
    "frame_files = sorted(f for f in os.listdir(sample['path']) if f.endswith('.png'))\n",
    "\n",
    "# Select three frames evenly spaced through the sequence\n",
    "indices = [0, len(frame_files)//2, len(frame_files)-1]\n",
    "selected = [frame_files[i] for i in indices]\n",
    "\n",
    "# Load and plot\n",
    "plt.figure(figsize=(9, 3))\n",
    "for i, fname in enumerate(selected):\n",
    "    img = plt.imread(os.path.join(sample['path'], fname))\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Frame {indices[i]+1}\")\n",
    "plt.suptitle(f\"Subject {sample['subject']}, {sample['condition']}, View {sample['view']}°\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3f897f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "IMG_HEIGHT = 64\n",
    "IMG_WIDTH  = 44\n",
    "\n",
    "def preprocess_frame(image_path):\n",
    "    \"\"\"\n",
    "    Reads an image file, decodes, resizes, and normalizes it.\n",
    "    \"\"\"\n",
    "    # Read & decode\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=1)            # grayscale\n",
    "    # Resize\n",
    "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    # Normalize to [0,1]\n",
    "    image = image / 255.0\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2f9d52a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 44, 1), dtype=float32, numpy=\n",
       "array([[[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]], shape=(64, 44, 1), dtype=float32)>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_frame(os.path.join(sample_path, sample_frames[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c25c47a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (9178, 30, 64, 44, 1)\n",
      "Train labels shape: (9178,)\n",
      "Test data shape: (4378, 30, 64, 44, 1)\n",
      "Test labels shape: (4378,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_HEIGHT = 64\n",
    "IMG_WIDTH  = 44\n",
    "SEQ_LEN    = 30\n",
    "\n",
    "def preprocess_frame(path):\n",
    "    # Read & decode\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    # Resize & normalize\n",
    "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    image = image / 255.0\n",
    "    return image.numpy()  # convert to NumPy\n",
    "\n",
    "def build_dataset(entries):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for ent in entries:\n",
    "        # Get sorted frame file names\n",
    "        files = sorted([f for f in os.listdir(ent['path']) if f.endswith('.png')])\n",
    "        # Truncate or pad to SEQ_LEN\n",
    "        files = files[:SEQ_LEN]\n",
    "        while len(files) < SEQ_LEN:\n",
    "            files.append(files[-1])\n",
    "        # Preprocess frames\n",
    "        seq = []\n",
    "        for fname in files:\n",
    "            img_path = os.path.join(ent['path'], fname)\n",
    "            img = preprocess_frame(img_path)\n",
    "            seq.append(img)\n",
    "        seq_array = np.stack(seq, axis=0)  # (SEQ_LEN, H, W, 1)\n",
    "        X_list.append(seq_array)\n",
    "        y_list.append(int(ent['subject']) - 1)  # zero-based label\n",
    "\n",
    "    # Stack all sequences\n",
    "    X = np.stack(X_list, axis=0)  # (N, SEQ_LEN, H, W, 1)\n",
    "    y = np.array(y_list, dtype=np.int32)\n",
    "    return X, y\n",
    "\n",
    "# Build datasets\n",
    "X_train, y_train = build_dataset(train_data)\n",
    "X_test,  y_test  = build_dataset(test_data)\n",
    "\n",
    "print(\"Train data shape:\", X_train.shape)\n",
    "print(\"Train labels shape:\", y_train.shape)\n",
    "print(\"Test data shape:\", X_test.shape)\n",
    "print(\"Test labels shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "864ec849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (9178, 30, 64, 44, 1)\n",
      "y_train shape: (9178,)\n",
      "Number of training samples: 9178\n",
      "Sequence length: 30\n",
      "Image size: 64 x 44\n",
      "Number of unique subjects: 84\n",
      "Subjects: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83]\n",
      "Sequences per subject: [110 110 110 110  95 110 110 110 110 110 110 110 110 110 110 110 110 110\n",
      " 110 110 110 110 110 110 110 109 110 110 110 110 110 110 110 110 110 110\n",
      " 100 110 110 110 110 110 110 110 110 110 110 100 110 110 110 110 110 110\n",
      " 110 110 110 110 110 110 110 110 110 110 110 110 110  89 110 110 110 110\n",
      " 110 110 110 110 110 110 105 110 110 110 110 110]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Shapes\n",
    "print(\"X_train shape:\", X_train.shape)  # (N, SEQ_LEN, 64, 44, 1)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(f\"Number of training samples: {X_train.shape[0]}\")\n",
    "print(f\"Sequence length: {X_train.shape[1]}\")\n",
    "print(f\"Image size: {X_train.shape[2]} x {X_train.shape[3]}\")\n",
    "print(f\"Number of unique subjects: {len(np.unique(y_train))}\")\n",
    "\n",
    "# Unique subjects in train\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"Subjects:\", unique)\n",
    "print(\"Sequences per subject:\", counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "dcdbd270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHQAAAEZCAYAAAD2XnKVAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAKLtJREFUeJzt3QmYZFV5N/DbOCAygKAO4spqQCJRwCUOIglRCODGBIPKIioGUBFxQQwk7BrCoog6gDEDCiiCA4I64jZGAmIkQkSTuCAzCi6DijIMDAxa3/O/31f9VVUv0z1dPdWn6vd7nn66ltt1T906p2/VW+95z1Cj0WhUAAAAABRjnV43AAAAAIDJEdABAAAAKIyADgAAAEBhBHQAAAAACiOgAwAAAFAYAR0AAACAwgjoAAAAABRGQAcAAACgMAI6AAAAAIUR0AGACTj00EOrLbfcstfNYAB8/etfr4aGhqorr7xytdvqlwAwuAR0AJhRLrroovrDbPNn1qxZ1ZOe9KT6g+tdd93V6+bNKLfddlu1//77V1tssUW1/vrr18fpxS9+cXXeeef1umkD5e67766OPvroavvtt68e9ahHVZtttln13Oc+t3r3u99d3XfffVXJLrvssuoDH/jAhLf/0pe+VL3hDW+onvGMZ1SPeMQjxg02/fjHP67776abblptsMEG1Qte8IJq8eLFXWo5APS/Wb1uAACM5pRTTqm22mqrauXKldVNN91UB3r+/d//vfre975XBy8G3Y033lj95V/+ZfXUpz61euMb31htvvnm1c9+9rP6WJ177rnVUUcd1esmDoTf/va31bOf/ezq3nvvrV7/+tfXQZ3f/OY31Xe/+91q/vz51ZFHHlltuOGG07b/j370o9Uf//jHaQ3oZMy97W1vm/D2l19+ebXzzjtXT3ziE8fcLn31+c9/fh30ede73lXNnj27WrBgQbXnnntWX/3qV6sXvvCFXXwWANCfBHQAmJH23nvv+oNyHHbYYdXjHve46owzzqiuueaa6m//9m+rQXf66adXj370o6tvf/vb1SabbNJ237Jly3rWrkHzsY99rPrpT39a3XDDDdXcuXPb7kuQZ7311pvW/a+77rrVTPLe9763DjKlXS95yUvqYNBo/umf/qn63e9+V9+/3Xbb1bclMJmA2DHHHFP953/+51puOQCUx5QrAIqw22671b9vv/324dseeuih6h//8R+rXXbZpQ5u5Fv+bNc5bWPJkiX19K2zzjqruvDCC6ttttmmeuQjH1k95znPqQMina6++up6ykgygfL7qquuGrVNK1asqN7xjndUT3nKU+rHywfT7KPRaLRtl32/5S1vqa644opqhx12qKflJDshU6biggsuqLbddtt6f3/xF39Rt3d1chz+9E//dEQwJzLlp9Mll1xSH6fs+zGPeUz1qle9qs6S6NQ8Ptku04auv/76uk356ZwW19nOZu2X/G71rW99q/rrv/7r+jXK1Jrdd9+9DoC0Oumkk+q/zTScTK/L88r2r3vd66r7779/1OeT9uXxMmUnGR2Z7tNq0aJFdX9Iv9hoo42qfffdt/r+979fdVNeh2SZ/Pmf//mI+zbeeOO2bLJMP8pz69R5fJv+8Ic/VH//939fZ1/lObzsZS8b8ZqNVkMnGTuZJpX+kf0//vGPrw4//PDqnnvuGbGPHKO8Hjk+aW/GRLJsmu36/Oc/Xy1dunR4CuTq6vUkK2ciQab0q5122mk4mBN5LfMcv/Od71Q/+tGPVvsYADDoBHQAKEIzeJAP760ZEP/yL/9Sf/BM9k6CAqlnstdee1W33nrriMfIB9Uzzzyz/nB72mmn1Y85b968atWqVcPbJCjwN3/zN/WH1/e9733VK17xijqocPPNN7c9VoI2+fD5/ve/vw5WnHPOOfWH00wfefvb3z7qB9gEf1772tfW7fyf//mfOoPhwx/+cPXBD36wetOb3lT/7Te/+c166s7qpG5OshjGyoDozOY55JBDqqc97Wl1OzN9pjmtJVkSrdkmOTYJIPzzP/9zteuuu44aRJiMr33ta/V+8lqdeOKJdQZH9rnHHntU//Ef/zFi+2RfLV++vD72uZzg0cknn9y2Ta4ffPDBdeAgU/NyPUG17KvpE5/4RB3AyXSn9I1/+Id/qP77v/+7rtMykYDZROV1SOAl++u2vG4JqKQWz1vf+tbqy1/+cvWiF72oeuCBB8b9u7yG6Ut5/TL9Lv330ksvrcdFa1/Psc0xyrSx97znPXXWzLOe9azqi1/8Yn3/8ccfX19PdlyeX34mU09nPA8++GAdNOyUoE7I0AGACWgAwAyyYMGCpLc0vvKVrzTuvvvuxs9+9rPGlVde2ZgzZ07jkY98ZH296eGHH248+OCDbX9/zz33NB7/+Mc3Xv/61w/fdscdd9SP+djHPrbx29/+dvj2z372s/Xt11577fBtz3rWsxpPeMITGr/73e+Gb/vSl75Ub7fFFlsM33b11VfXt5122mlt+99///0bQ0NDjR//+MfDt2W7tD3taLrgggvq2zfffPPGvffeO3z7e97znvr21m1HkzY94hGPqH+e//znN4499tjGdddd13jooYfatluyZEm9zemnn952+2233daYNWvW8O35u80226x+/q3H9MILL6zbs/vuu494jTrbuHjx4vr2/I4//vGPjac97WmNvfbaq77cdP/99ze22mqrxotf/OLh20488cT6b1tft9hvv/3q163pRz/6UWOdddapb//DH/7Qtm1zH8uXL29ssskmjTe+8Y1t9//yl79sPPrRjx5x+1TkMdM30/btt9++ccQRRzQuu+yytv7TlP7z2te+dsTtObatx7d5HJ/0pCe19Y1Pf/rT9e3nnnvu8G15vNZ+ef3119fbXHrppW37+OIXv9h2e9q30UYbNZ73vOc1HnjggbZtW1+rfffdt+3xJ2O8v33pS19av0atzy/Sl9POs846a432CQCDRIYOADNSMhHmzJlTZ15kJZxMOUn9nCc/+cnD22SqS7NGSaaZJNPg4YcfrmvvZNpGpwMOOKAtw6c5jesnP/lJ/fsXv/hFndmTLJpM92nKylGZKtXqC1/4Qr3/ZE60ShZOYjiZytLqr/7qr9qmqzzvec+rfycbKNNdOm9vtmksaVOyeZJB81//9V91Rk0yMLLSVY5T08KFC+tjk2yXX//618M/ycJJxk5zeloykFJ754gjjmir+5IpPa3HYjJyLDN15jWveU1dKLi570xVy/H4xje+MaKgb/bfKq9R/jYZPs3pcPmbTLVbZ532tzHJqopksiQL6NWvfnXbc87rlePbzZWUMp0pxz/tzpSm888/v36+mfZ26qmnjph+NxnJqmrtGxkHT3jCE+q+N5ZM68vrlf7R+twz3S7ZSs3nnmOUTKjjjjtuRJHx5nGcTikWndcoY/KWW26pfvjDH9aZY81MuNVlIQEAiiIDMENlKtKf/MmfVL///e+rf/3Xf60//KdOTaeLL764Ovvss6v//d//bZtOkhWyOmVFqFbN4E6ztkhqhUQCHZ0ynao1SJRtUy+k9QN3PP3pT297rLH23QySJGA12u2j1TvplHonCdikllCCCqn1kylg+eCfYEqCUAmoJKgw2nOKZr2TsZ577t96662rNdGsg5IA2Vjy+rYG2cZ7jVLjJTVrEsjpDLCNtt9M6xpNHmcsmT6VaXutUnNovOLGCbJkRauPfOQj9b6vu+66eppXgk65L0W910Tna5FAS2otjTdlLPvPMR2tjlJrwexmLarUiOpV0fPzzjuvDihlRazIc8s0s2OPPXZaVwYDgH4xEBk6zeKNo/3kjUQ/uO++++raBKnjkDeeeW553lC6QRi/zQ9hKVKb7JPUkMhKL6kNMlox2EGRgrfJ0kkGSzJO8sEzmQ/5f9daGDcZJCnim/ovqf2RzIN8kB9tKedkaIxmKlkUEzXWvrvRpgQbEtxJfZoEFhLYSqZG5DhkvDSPTedPCjJP1mgZHBmrWUY98jvbJPsiUuNotH3np/ODezeOR/O1T82X0fb52c9+dsy/Tb2gBGFaf7JE/ETOtbmeIGSWjG9mWmXlpub/rATNRiuwnSBSt+S5J5gz1vHO/5WZIoXCf/WrX9XHN5k5Cco2A5o5jqxdg3C+TRH89LsUDE/WZwLIyV5MhljnOMrxSAZkgu7ZNueg1F5buXJlz9oPgzx+s6jBK1/5yvpLprxXTn23F77whdW111476vapVZjzdd5n5Jyd2nudX9j0g4HK0MmbmM5vbHv1zVS3JZ06zy8npmc+85kjVhiB0vXz+M0HyAQv8kEmbzRz0slUmnxwTGHQ8T58Dop8yE+R3AQKPvShDw2/ObnyyivrE3uyVFqDDDl2a1rgNkZbYecHP/jBiG2/8pWv1NNWWrN08qG09bHWtuZS75k+Fgl2JRiS8TPeh+TW596a2ZLg0B133FGfWzqzZloLKrfKykzJVMq0sbwWKUSc4Fw35Pnkw1YKHKdg71jbRAIbk91vpqIl8NGq+dwnc65t9okEhDIdLk444YT68Tsl0DNaFlRnP8zrmFXA/uzP/mzM/ea5p1+mIPJoRYdbt4sU1U5mzFime/pVPihnxbemtD3tTvvpjX4+3yZzLivs5UNhxtEvf/nL+pySLLGbbrpp+Hnmy5QUE8/qdZlOmf8lzfNyCsqnAPvamJoIk9XP4zfnyrznStZvMqQzTj/zmc/Ugdd8OfV3f/d3w9veeeeddbAn763zZVe+kMkqpFldNAsyjJd1W5zGAGgWb/z2t7894b9JgcDOYosz2cqVKxu/+MUv6st5nnm+ed5QukEYvylKm+f4ve99r+32Qw45pL69tYjvoL/mz33uc+uCx80irvPmzWtsvfXWba/3TTfdVBclbi3G2iyKfOaZZ454zNyegrxrWhT5ve99b9vjHXDAAaMWRX7zm9/ctt1YbWoWxL3iiivGPU5f+9rX2orXNp1xxhn1359zzjn19bQjRZFf85rXjNg+13/9618PF0VOcd+JFEVOX+0szvuxj32svq21KHJel2222aYujJxCxZ1++tOfDr92zaLIKYTdqrMA80SKIv/+979vbLzxxnWbO4tEx7JlyxrdOteecMIJjfvuu2/Etvvss099/8te9rK2gtnpv63HNwW5O4/v6ooif+ADHxizKPLXv/71epsU1+60atWqumh48xilKHLG1HhFkdOfU7x4TUy2oPINN9xQ99W3vOUta7Q/pmYQzrfpY52F9H/4wx/WResPPPDA4duyTbbtdPLJJ9fH6Mtf/vJaaS9M1CCM39E8/PDDjWc+85mN7bbbru32I488svGoRz2qsXTp0uHbMm5zjLIoRT8ZiClXq5Nv2BJl/9SnPlV/e5aCkknjSgHGFNh85zvfWe244451ulbm3Wfed2oVjPYYn/70p+vlU/MY+XYudQwylz3Lc6bYXyL8eZxE/XNbp0wfSOHCfDuVb+kzBWMiy8WmrsRo3/pBv+uH8dss9priqq3yzX5qhfTVtwhTlKWYM0WjOc0ly34nC2S//farLrzwwnrp5aTXjldfZXWSCZR9JKsk9Wiy3HW+zU2KfquXvvSldcZQlnbOMtGpn5Ilzi+//PLq6KOPHs6AmC6Z1pN9pAjzRz/60brm0IEHHlhnx6T4cvppZJtME8iS7XlOWbY9hXuzFHbqAi1YsGC4Vk62S+2dZOikvkmWX089k87skRyLfHOd450l2LPser4B65T+m2XlMw6SBZJxlilI+dYs561kujTHapaLb2YKjTdWU1cmr3emLqWYbx4nmTopgJy2ZqxmXxmjqbu000471XVZ0j/yPyLXM3WvW+faTBfKVMksNZ/XIK9FjlszyyfHuTnGU0snfSt9NK9B+nOOx1h9JW3La5alwnOsUyQ5zy1/M5bdd9+97o/px/vss0/9t2lXjkszqyxyjNO/801lputl+7QpxYozjbEpxymZWHlOn/zkJ8dMbW/67ne/W/ej/CSbKP9Dm9db/zbftGZaWl6bTJfM4yebKlkTo/Uleq8fzrdz584dcU7N/5T8T8v0jKZsk2075X9PtG4LJeiH8TtWBvdTnvKUERnDydzJe8TWunw5xyRTOe3vK40BXAK39af1m7Addtih/mYy32q+733va6xYsaKOcubbxeOOO66O5p1yyin1N2ZZ9vSuu+4a3kfzMfL3WXLzgx/8YOOtb31r/S3tq171qvqb0b333rvx4Q9/uHHwwQfX2ybK3ypL32b7fBv2kY98pL7/cY97XGPLLbcc/kZtImTo0E8GYfwuWrRo+Jv8W265pc5a+NSnPlVnGLztbW9rDJrxvmVqZnzkJ9/KJJMgGTLJAsg3rDvttFPjc5/73Iishclk6MRnPvOZxtOf/vT6MdO3Fi5cOOIxI1knxxxzTOOJT3xiY911160zUbKPzkyY6cjQSb/JEt9ZKnvDDTdsrLfeeo1tt922cdRRRzV+9atfjdg+z+kFL3hBY/bs2fVP/i5t+sEPftC2XfpvlhTPc3/2s5/d+MY3vjFiWe24/fbbGy960Yvq7ZJ18pKXvGQ4QyfZS61jNf16t912q+/LOMmxyng77LDDhsfqpptuWt9/9tlnt43VjOlmhk7rWE0fePKTn1xndOS2ZBftscceI8ZqjkkeZ/3116//Jn0kt3frXJu2vutd72rsvPPOjcc85jH1UvDJ8Epfyf0bbLBB/TvP701velPdX/Pcctx23XXXxs033zzmsuWf/OQn60ybLCefbxqT8dL6bWOM1i+bmVW77LJL/XfJxNlxxx3rpe1//vOft213zTXXNObOnVtvl/85ydjJfpuSfZT/gcnS6cxSG2/8jvbTumR7Mg9f/vKXNzbffPO676bPvfvd7x6xjDlrzyCcb0eT/9dp65577rnabZvZmpdddtmk9wPTaZDGb85LeV7JQD7nnHOGs5Cb7rzzznrfyVjudNBBB9Xn6n4yUAGd0X5aO2fS9u+///4R6dWdqWh5U5k3YunsTc3HeMYzntGW3v3qV7+67rTp3K0yCFrfFC1ZsqTujJl60eq2226r3xx23j4eAR36yaCM31NPPbX+QNX6/I4//vgJHyeYTqMFdAZ1rE70XJs3xglQXH755XWAJMGMbJ8gTqY+dUvenOaNOEzVoI3hpk984hN1mzJtdHUSxE7gc00CRzCdBmn8Hn744cPPbZ111qmnM7eWJ2ienz/+8Y+P+Nt8AZP78pz7xaxBXAJ3LCmw1FlAsHWJ3KxCkXSupJB1Ll/blHTo5hKwkXTipCgnFbtVbk+K+sMPP1zNmjWrLuiZIo+ptJ+ii01J7U4q6OLFi+s0ehhU/T5+M0Um01CyotNjH/vY6vOf/3w97SCPkULJUIp+H6sTlSlMrZJSnuOSKXop5p3r3ZDi11npA7plkMZwiti/+c1vrgtz53mNJ+fkTFnM9NpNNtlkwvuAtWkQxm+mdWWa189//vN6+lTa/NBDDw3f/8ADD4x4Xk2Zqt3cZrT7SzRQAZ2sItNc/WM0nRXBI53u3HPPrf95Z5WP1qVF86GrU+s8vWguv5m5fZ2357Ez3zCPk5UskjGVzjya1kEDg6ifx2/mM6cyf5ZNTS2OmDdvXr2P1N9IbZDR2gszUT+P1ak65phj6ppM+VA41YBOatVcffXVdZ2g1OKBbhmUMZwVrvbdd996HwmyphbHWFIbLXVH3vCGN9R1pmCmGoTxu/3229c/zeDSnnvuWdc1/Na3vlXX+GkGrEar37Ny5cr693irQJZmoAI6qzPaC5tofN58JeJ46qmn1oWbUuQxkcF00E5jnQzGuv3/llb4vwMpHXDRokWjbpsoKdCf4zcn0BRqbQZzmrIMY4r/3nLLLV1b8hl6reSx2o3nnje1KUA5VfmmM4WrExhKwWRYW/phDOcDZoq+JhPh+uuvr5dAHksKnOdDY4I/KRwOJeuH8dtp//33rxcDyBejySrKoiLNDNZOuS3Pr1+yc0JAZzUSsc8qJlmBoVVOAN1Mcc4KF+nsiZqOlyYH9N/4zao3m2666YjbV61aVf9Oqir0Ula2mE6ljNWpWr58eZ1mPmfOnCk/VlYXyw/MBCWN4XxDn2/z8+Ev2XLjrYqYb/yzslUyHjK1I9NGoN+UNH5H88D/m2KVQG1k9a2cZ2+++eYR22Zlx6yM2U8sW74aiR42o4pNV1xxRXXXXXd1dT+ZXpF9ZQm4zv3l+m9+85uu7g8GQSnjNye1ZOHkzWWrzEfONyRZxhf6WSljdTIfGBO86ZRvPrOfLFsO/aSUMZypJAcccED1zW9+s25faueMJUuTJysnNe4+97nP9dUUDShx/C5btmzULz8//vGP1+OzNTibmpQZt63LoX/1q1+t32u/8pWvrPqJMPNqZP36U045pXrd615XzZ07t7rtttuqSy+9tNp66627up9ELE877bQ6bXrJkiXVK17ximqjjTaq5zFeddVVdX2Nd77zneM+xoc+9KE6kpoCUXHttddWd955Z335qKOOGp7fCIOilPGb+hdJP91tt93qAsiZkpGTUG477LDDxk0Fh35Qylid6Lk2tTkyjTL1r5rz/K+77rrqC1/4Qh3MefnLX97V5wW9VsoYfsc73lFdc801dYZOpj5ecsklbfcfdNBB9e8EZPfaa6/qnnvuqc/RWaigsx3jBYOgJKWM30yruvfee+tFRJKFk3PtpZdeWhc3P/vss9umbKW4coJSyTw6+uijq/vuu68688wzqx133LF+nv1EQGc10hlWrFhRXXbZZXVBtJ133rn+p37cccd1fV95zHxT//73v7+OXDaLS6XQU2pprM5ZZ51VLV26tG1+fX6aJygBHQZNKeM3J6Ybb7yxnj6Rejr5hiLpqKeffnp17LHHdr2tMNOUMlYneq7NCjh5g5zaGxdffHGdFbDtttvWdQryZjWZd9BPShnDt95663AgNj+dmgGdnIeb3+yP9hyyUpCADv2ilPGb7LpMC5s/f349RhMM2mWXXaozzjhjxN/mMf/t3/6tevvb317vc7311qsz7hL46af6OTGUtct73QgAAAAAJs5XRAAAAACFEdABAAAAKIyADgAAAEBhBHQAAAAACiOgAwAAAFAYAR0AAACAwgjoAAAAABRm1kQ3HBoamt6WwBgajUavm9AXjGF6xRieOuOXXjF+u8MYpleM4akzfpnJ41eGDgAAAEBhBHQAAAAACiOgAwAAAFAYAR0AAACAwgjoAAAAABRGQAcAAACgMAI6AAAAAIUR0AEAAAAojIAOAAAAQGEEdAAAAAAKI6ADAAAAUBgBHQAAAIDCCOgAAAAAFEZABwAAAKAwAjoAAAAAhRHQAQAAACiMgA4AAABAYQR0AAAAAAojoAMAAABQGAEdAAAAgMII6AAAAAAURkAHAAAAoDACOgAAAACFEdABAAAAKIyADgAAAEBhBHQAAAAACiOgAwAAAFAYAR0AAACAwgjoAAAAABRGQAcAAACgMAI6AAAAAIUR0AEAAAAojIAOAAAAQGEEdAAAAAAKI6ADAAAAUBgBHQAAAIDCCOgAAAAAFEZABwAAAKAwAjoAAAAAhZnV6wYwOBqNxvDloaGhnrYFAKZi2bJlbdfnzJkzfNk5DgBYG2ToAAAAABRGQAcAAACgMEON1nkw420ofZhJGq9rXXXVVW3X582bt0aPw8QZw4Pj4osvHr58yCGH9LwfGMNTZ/zOPOP16356vYzf7uinPrG2HXrooW3XFyxY0HbdsR2fMTx1+hgzefzK0AEAAAAojIAOAAAAQGEEdAAAAAAKo4YOM2LO7nj9y9zf7jCGB8dMq+1hDE+d8du/deJmOuO3O4zh6euDRxxxxPDlCy64YC20qCzG8NQN4vhdXb8ZxGPSC2roAAAAAPQhAR0AAACAwgjoAAAAABRGDR2mjRo6M4sxPDjGGzMbbrhh2/UVK1b0tD1MjPE786ihw2QYw71/PzmojOGpG8R+pYbOzKCGDgAAAEAfEtABAAAAKMysXjeAwfSd73yn100AgGlR8hQrKM15553X6yYA9IwMHQAAAIDCCOgAAAAAFEZABwAAAKAwli1n2ozXtSbTnyy32B3G8ODo1tjrFmN46ozfmWemjbPpYvx2Rz/1ibXN8slTYwxP3SD2MeNuZrBsOQAAAEAfEtABAAAAKIxly5k2nal4Uj4BAACgO2ToAAAAABRGQAcAAACgMAI6AAAAAIVRQ4eeWLFiRdv12bNn96wtANBNCxcubLs+b968nrUFAOhfMnQAAAAACiOgAwAAAFAYAR0AAACAwgw1Go3GhDYcGpr+1tBXJti1Vtu/JvM4jM0YHhzjjZn111+/7fqDDz7Y0/YwMcZv/57jZjrjtztK7gO9NihjbboYw1M3iP1qdf1mEI/JTB2/MnQAAAAACiOgAwAAAFAYy5YDDJCVK1e2XZcyCwDAZCxcuHD48rx583ralkEnQwcAAACgMAI6AAAAAIUR0AEAAAAojBo6AAAAMMBOOumkCW+73377TWtbmDgZOgAAAACFEdABAAAAKIwpVwCF23rrrXvdBBgIk0lHBwCYbjJ0AAAAAAojoAMAAABQGAEdAAAAgMIMNRqNxoQ2HBqa/tbQVybYtVbbvybzOIzNGB6cGjq33377jOoXxvDUGb8zw5r25T322KPt+uLFi6tSGL/dYQxPTut5bDJ14hznkYzhqRuUfrWmfWVQjs9MfU1k6AAAAAAURkAHAAAAoDACOgAAAACFmdXrBgAwNZOpmQOsfdttt12xNXSgFyZTNwdgkMnQAQAAACiMgA4AAABAYQR0AAAAAAojoAMAAABQGAEdAAAAgMII6AAAAAAUxrLldM1JJ53U6yYAAADAQJChAwAAAFAYAR0AAACAwphyRddcffXVbddPPPHEnrUFAAAA+pkMHQAAAIDCCOgAAAAAFEZABwAAAKAwaujQNbfeemuvmwBM0t577z18edGiRT1tC8w0jUaj100AABiTDB0AAACAwgjoAAAAABRGQAcAAACgMGroAAywE044YfiyGjoA9ML8+fN73QSAIsnQAQAAACiMgA4AAABAYUy5AijQqlWret0EAOiKI444otdNACiSDB0AAACAwgjoAAAAABRGQAcAAACgMGroABRo1iz/vqHbLrrool43AQBgwmToAAAAABRGQAcAAACgMHL2AQo0NDQ0fLnRaPS0LdAvDjzwwF43AQBgwmToAAAAABRGQAcAAACgMAI6AAAAAIVRQwcAoKqqddddt+26+lSwdixfvrzt+kYbbdSztgCURIYOAAAAQGEEdAAAAAAKI6ADAAAAUBg1dAAARrHVVlu1Xb/jjjvW6HHOP//8LrUI+tPGG2/cdn3p0qXDl5/61Kf2oEUAZZChAwAAAFAYAR0AAACAwgw1Jrgm59DQ0PS3hr4yXteaTH+ybGx3GMP9aypjZJ999hm+vGjRomo6GMNTZ/zODGval0t+/Yzf7ii5D8z0PujYjs8YnrpB6WODeI7rh9dEhg4AAABAYQR0AAAAAAojoAMAAABQGDV0mDZq6MwsxnD/msoYWRv9whieOuN3ZhjE+gLGb3eU3Ad6TQ2dqTGGp25Q+th4fWX99ddvu75y5cqBOz69oIYOAAAAQB8S0AEAAAAojIAOAAAAQGFm9boBAKw95jnDxM2dO7fXTQCAtV6fZZdddmm7/uCDD4657fHHH992/fTTT+9C65goGToAAAAAhRHQAQAAACiMZcuZNpYtn1mM4f7VrbE2XYzhqZsJr+Mg6pxydcMNN4z5msz0cbimjN/uKLkPzLQ+eMkll7RdP/jgg9dyi8piDE9dv47fqZy3+vWcN9NYthwAAACgDwnoAAAAABRGQAcAAACgMJYtp2tOOumkXjcBBsZ4c2oXL1485n0XXXTRmPcdeuihU24XAEyn5zznOb1uAsCMIUMHAAAAoDACOgAAAACFsWw50zbl6sQTTxxzW8uWr33GcH9Z0+Uie7HMpDE8dcZvb8yZM6ft+rJly4YvW7acySi5D8z0PujYjs8Ynrp+7WPdOm91Ps7GG288fHn58uVr2DrCsuUAAAAAfUhABwAAAKAwAjoAAAAAhVFDh+LmZbJmjOH+sqbj6/vf/37b9R122GH48sknnzxuXaw1ZQxPnfHbG3Pnzm27fsMNNwxfVkOHySi5D5TUBx3nkYzhqevXftXZN1rfB07mPWC/nv9mAjV0AAAAAPqQgA4AAABAYQR0AAAAAAqjhg7TRg2dmcUY7i9rY3x1q88Yw1Nn/PaGGjrGb7eU3AdK6oOzZ89uu37//fdXg84Ynrp+Hb+dfWNNn2e/nv9mAjV0AAAAAPqQgA4AAABAYWb1ugEMpm6l+MGgmD9//pj3TWX8nHbaacOXTzjhhDV+HOhHN95444S3PeKII4Yvn3/++WPeN9r9QHesWLGi7br3lzD9JjMFme6ToQMAAABQGAEdAAAAgMII6AAAAAAUxrLlTJvJzJ8cr3+Zh9kdxnDZpmtJyNZlmVuXZJ7q47YyhqfO+J0ZWvty52vSulzyfffd13bfkUceWWwNHeO3O4zh6au72K33m/3KGJ66fu0301XTdLxzJZNj2XIAAACAPiSgAwAAAFAYU66YESmeW2211fDlJUuWrPHjMDZjuGzTNeVqvH3suuuua7yE83iPy+QZvzPDRNPIV9fnS3o9jd/uKOk1L3laSD+NvW4xhqeuX/vNdE25WrVq1fDlWbNmTcs+BkXDlCsAAACA/iOgAwAAAFAYAR0AAACAwrRPaoMeueOOO4Yvb7PNNj1tCzC9y5hDKebOndvrJgCTcP/997dd32CDDXrWFpiJNViWLl067fvccssthy/feeed076/QSdDBwAAAKAwAjoAAAAAhRHQAQAAACiMGjrMOD/5yU963QQYSCeffHLb9RNPPLFnbYFeOP/889uuH3744T1rCwyyiy66aMz75s+f33b9yCOPHL48e/bsaW0XlG6LLbaY9n0cffTR074P/j8ZOgAAAACFEdABAAAAKMxQo3Mts7E2tFwtkzRe15o3b17b9YULF47Z1ybYRVkNY3jmO/DAA4cvr7vuum33LViwoO36ZpttNnz57rvvnpb2jDf2JtOfjOGpM37XjlWrVrVdnzVr1hq9Jqvr8yW9nsZvd5T0mpfW71qPbeffOe7GcDf0Uz9qnc64zz77jPnecia8f6Sa0PiVoQMAAABQGAEdAAAAgMII6AAAAAAURg0dZsQc3YMOOmj48qWXXtq1x+X/M4b7t2bA2tr/mu7TGJ4647c3JlMHoNfjd7oYv91R0ms+0yxZsmTc+7fccsu11pYSGcNTZ/zSK2roAAAAAPQhAR0AAACAwphyxYxI6ZzK8q9MjDE88/V6yoYpVzOX8Tvz9Xr8ThfjtztKes3pL8bw1Bm/9IopVwAAAAB9SEAHAAAAoDACOgAAAACFmdXrBjA480sPPfTQ4csLFixYCy2CsvR6jnav9w8lM34AgLVNhg4AAABAYQR0AAAAAAojoAMAAABQmKHGRBY3NzecHppgF2U1jGF6xRieOuOXXjF+u8MYpleM4akzfpnJ41eGDgAAAEBhBHQAAAAACiOgAwAAAFAYAR0AAACAwgjoAAAAABRGQAcAAACgMAI6AAAAAIUR0AEAAAAojIAOAAAAQGEEdAAAAAAKI6ADAAAAUBgBHQAAAIDCCOgAAAAAFEZABwAAAKAwAjoAAAAAhRHQAQAAACiMgA4AAABAYQR0AAAAAAojoAMAAABQGAEdAAAAgMII6AAAAAAURkAHAAAAoDACOgAAAACFEdABAAAAKIyADgAAAEBhBHQAAAAACiOgAwAAAFAYAR0AAACAwgjoAAAAABRGQAcAAACgMAI6AAAAAIUR0AEAAAAojIAOAAAAQGEEdAAAAAAKI6ADAAAAUBgBHQAAAIDCCOgAAAAAFEZABwAAAKAwAjoAAAAAhRHQAQAAACiMgA4AAABAYQR0AAAAAAoz1Gg0Gr1uBAAAAAATJ0MHAAAAoDACOgAAAACFEdABAAAAKIyADgAAAEBhBHQAAAAACiOgAwAAAFAYAR0AAACAwgjoAAAAABRGQAcAAACgKsv/AdhLfcINle57AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Pick a random sequence and show five frames\n",
    "i = random.randint(0, X_train.shape[0] - 1)\n",
    "seq = X_train[i]  # shape: (SEQ_LEN, 64, 44, 1)\n",
    "label = y_train[i]\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "indices = np.linspace(0, seq.shape[0] - 1, 5, dtype=int)\n",
    "for idx, frame_num in enumerate(indices):\n",
    "    plt.subplot(1, 5, idx+1)\n",
    "    plt.imshow(seq[frame_num,:,:,0], cmap='gray')\n",
    "    plt.title(f\"Frame {frame_num+1}\")\n",
    "    plt.axis('off')\n",
    "plt.suptitle(f\"Random Sequence - Subject {label}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3f804b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save training data\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('y_train.npy', y_train)\n",
    "\n",
    "# Save testing data\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_test.npy', y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4517c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes after loading:\n",
      "X_train: (9178, 30, 64, 44, 1)\n",
      "y_train: (9178,)\n",
      "X_test: (4378, 30, 64, 44, 1)\n",
      "y_test: (4378,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load training data\n",
    "X_train = np.load('processed/X_train.npy')\n",
    "y_train = np.load('processed/y_train.npy')\n",
    "\n",
    "# Load testing data\n",
    "X_test = np.load('processed/X_test.npy')\n",
    "y_test = np.load('processed/y_test.npy')\n",
    "\n",
    "print(\"Shapes after loading:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d023084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn on mixed precision training\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy(policy=\"mixed_float16\") # set global policy to mixed precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19cd25f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DTypePolicy \"mixed_float16\">"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_precision.global_policy() # should output \"mixed_float16\" (if your GPU is compatible with mixed precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d748f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique subjects (classes): 124\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_labels = np.concatenate([y_train, y_test])\n",
    "num_classes = len(np.unique(all_labels))\n",
    "print(f\"Number of unique subjects (classes): {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "617c5154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], shape=(4378, 124))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "y_train_onehot = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_onehot = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "y_test_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf109a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped X_train shape: (9178, 64, 44, 30)\n",
      "New shape: (9178, 64, 44, 30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,336</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5632</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">180,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,092</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m4,336\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5632\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │       \u001b[38;5;34m180,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m124\u001b[0m)            │         \u001b[38;5;34m4,092\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193,324</span> (755.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m193,324\u001b[0m (755.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193,324</span> (755.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m193,324\u001b[0m (755.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "SEQ_LEN = X_train.shape[1]  # number of frames per sequence\n",
    "HEIGHT = X_train.shape[2]\n",
    "WIDTH = X_train.shape[3]\n",
    "CHANNELS = 1\n",
    "NUM_CLASSES = y_train_onehot.shape[1]\n",
    "\n",
    "model = models.Sequential([\n",
    "    # TimeDistributed applies the same CNN to each frame in the sequence\n",
    "    layers.TimeDistributed(layers.Conv2D(32, (3, 3), activation='relu'), input_shape=(SEQ_LEN, HEIGHT, WIDTH, CHANNELS)),\n",
    "    layers.TimeDistributed(layers.MaxPooling2D((2, 2))),\n",
    "    layers.TimeDistributed(layers.Conv2D(64, (3, 3), activation='relu')),\n",
    "    layers.TimeDistributed(layers.MaxPooling2D((2, 2))),\n",
    "    layers.TimeDistributed(layers.Conv2D(128, (3, 3), activation='relu')),\n",
    "    layers.TimeDistributed(layers.Flatten()),\n",
    "\n",
    "    # Flatten all time steps\n",
    "    layers.Flatten(),\n",
    "\n",
    "    # Fully connected layer\n",
    "    layers.Dense(128, activation='relu'),\n",
    "\n",
    "    # Output layer with softmax for classification\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b84b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.89 GiB for an array with shape (9178, 30, 64, 44, 1) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 17\u001b[0m\n\u001b[0;32m     12\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     13\u001b[0m     EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     14\u001b[0m     ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m)\n\u001b[0;32m     15\u001b[0m ]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Create Dataset objects\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_onehot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mmap(preprocess)\n\u001b[0;32m     19\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mshuffle(buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:827\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;66;03m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m from_tensor_slices_op\n\u001b[1;32m--> 827\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensor_slices_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\from_tensor_slices_op.py:25\u001b[0m, in \u001b[0;36m_from_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_from_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 25\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_TensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\from_tensor_slices_op.py:33\u001b[0m, in \u001b[0;36m_TensorSliceDataset.__init__\u001b[1;34m(self, element, is_files, name)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     32\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[0;32m     35\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:134\u001b[0m, in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    131\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    132\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(spec, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    133\u001b[0m         normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 134\u001b[0m             \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(pack_as, normalized_components)\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:757\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[0;32m    756\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[1;32m--> 757\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    226\u001b[0m           _add_error_prefix(\n\u001b[0;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_tensor_conversion.py:29\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constant_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     28\u001b[0m _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:276\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconstant\u001b[39m(\n\u001b[0;32m    179\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[0;32m    181\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    288\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 289\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    292\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[0;32m    293\u001b[0m )\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_constant_eager_impl\u001b[39m(\n\u001b[0;32m    298\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[0;32m    299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase:\n\u001b[0;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 301\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:96\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to an `EagerTensor`.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mNote that this function could return cached copies of created constants for\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m  TypeError: if `dtype` is not compatible with the type of t.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     93\u001b[0m   \u001b[38;5;66;03m# Make a copy explicitly because the EagerTensor might share the underlying\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[38;5;66;03m# memory with the input array. Without this copy, users will be able to\u001b[39;00m\n\u001b[0;32m     95\u001b[0m   \u001b[38;5;66;03m# modify the EagerTensor after its creation by changing the input array.\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, ops\u001b[38;5;241m.\u001b[39mEagerTensor):\n\u001b[0;32m     98\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.89 GiB for an array with shape (9178, 30, 64, 44, 1) and data type float32"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eafb41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.89 GiB for an array with shape (9178, 30, 64, 44, 1) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_onehot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_onehot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     23\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:96\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to an `EagerTensor`.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mNote that this function could return cached copies of created constants for\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m  TypeError: if `dtype` is not compatible with the type of t.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     93\u001b[0m   \u001b[38;5;66;03m# Make a copy explicitly because the EagerTensor might share the underlying\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[38;5;66;03m# memory with the input array. Without this copy, users will be able to\u001b[39;00m\n\u001b[0;32m     95\u001b[0m   \u001b[38;5;66;03m# modify the EagerTensor after its creation by changing the input array.\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, ops\u001b[38;5;241m.\u001b[39mEagerTensor):\n\u001b[0;32m     98\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.89 GiB for an array with shape (9178, 30, 64, 44, 1) and data type float32"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Set training parameters\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 10\n",
    "\n",
    "# Callbacks for better training\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train_onehot,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_test, y_test_onehot),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c42bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "Available GPUs: []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Available GPUs:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b84d6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected by TensorFlow.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"{len(gpus)} GPU(s) detected and memory growth enabled.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU detected by TensorFlow.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb183ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
