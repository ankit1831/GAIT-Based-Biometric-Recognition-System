{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d85eb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 730 training sequences from 74 subjects\n",
      "Loaded 500 testing sequences from 50 subjects\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def load_casia_b_data(dataset_path):\n",
    "    \"\"\"\n",
    "    Load CASIA-B silhoutte data and split into training and testing lists:\n",
    "      - Training: Subjects 001–074\n",
    "      - Testing:  Subject 075–124\n",
    "\n",
    "    Returns:\n",
    "      train_data: List of dicts for each training sequence\n",
    "      test_data:  List of dicts for each testing sequence\n",
    "    \"\"\"\n",
    "    # Define subjects\n",
    "    train_subjects = [f\"{i:03d}\" for i in range(1, 75)]\n",
    "    test_subjects  = [f\"{i:03d}\" for i in range(75, 125)]\n",
    "\n",
    "    # Define conditions and sequences\n",
    "    conditions = {\n",
    "        'nm': [f\"nm-{j:02d}\" for j in range(1, 7)],\n",
    "        'bg': ['bg-01', 'bg-02'],\n",
    "        'cl': ['cl-01', 'cl-02']\n",
    "    }\n",
    "\n",
    "    # All 11 views: 0°,18°,…,162°,180° (padded to three digits)\n",
    "    views = [\"090\"]\n",
    "\n",
    "    def gather_entries(subject_list):\n",
    "        entries = []\n",
    "        for subject in subject_list:\n",
    "            subj_path = os.path.join(dataset_path, subject)\n",
    "            if not os.path.isdir(subj_path):\n",
    "                continue\n",
    "            for cond, seqs in conditions.items():\n",
    "                for seq in seqs:\n",
    "                    seq_path = os.path.join(subj_path, seq)\n",
    "                    if not os.path.isdir(seq_path):\n",
    "                        continue\n",
    "                    for view in views:\n",
    "                        view_path = os.path.join(seq_path, view)\n",
    "                        if not os.path.isdir(view_path):\n",
    "                            continue\n",
    "                        # Count silhouette frames (.png)\n",
    "                        frames = [f for f in os.listdir(view_path) if f.endswith('.png')]\n",
    "                        if frames:\n",
    "                            entries.append({\n",
    "                                'subject':   subject,\n",
    "                                'condition': cond,\n",
    "                                'sequence':  seq,\n",
    "                                'view':      view,\n",
    "                                'path':      view_path,\n",
    "                                'num_frames': len(frames)\n",
    "                            })\n",
    "        return entries\n",
    "\n",
    "    train_data = gather_entries(train_subjects)\n",
    "    test_data  = gather_entries(test_subjects)\n",
    "\n",
    "    print(f\"Loaded {len(train_data)} training sequences from {len(train_subjects)} subjects\")\n",
    "    print(f\"Loaded {len(test_data)} testing sequences from {len(test_subjects)} subjects\")\n",
    "    return train_data, test_data\n",
    "\n",
    "# Example usage:\n",
    "data_root = r\"D:\\vit study\\Machine Learning\\Gait\\CASIA - B\\CASIA - B\\GaitDatasetB-silh\\GaitDatasetB-silh\\GaitDatasetB-silh\"\n",
    "train_data, test_data = load_casia_b_data(data_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19949f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 730 sequences, Test: 500 sequences\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_casia_b_090_df(dataset_path):\n",
    "    train_subjects = [f\"{i:03d}\" for i in range(1,75)]\n",
    "    test_subjects  = [f\"{i:03d}\" for i in range(75,125)]\n",
    "    conditions = {\n",
    "        'nm': [f\"nm-{j:02d}\" for j in range(1,7)],\n",
    "        'bg': ['bg-01','bg-02'],\n",
    "        'cl': ['cl-01','cl-02']\n",
    "    }\n",
    "    view = '090'\n",
    "    def gather(subjects):\n",
    "        rows = []\n",
    "        for subj in subjects:\n",
    "            for cond, seqs in conditions.items():\n",
    "                for seq in seqs:\n",
    "                    path = os.path.join(dataset_path, subj, seq, view)\n",
    "                    if os.path.isdir(path):\n",
    "                        frames = [f for f in os.listdir(path) if f.endswith('.png')]\n",
    "                        if frames:\n",
    "                            rows.append({'subject':subj,'condition':cond,'path':path,'sequence':seq,'view':view,'num_frames':len(frames)})\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    train_df = gather(train_subjects)\n",
    "    test_df  = gather(test_subjects)\n",
    "    print(f\"Train: {len(train_df)} sequences, Test: {len(test_df)} sequences\")\n",
    "    return train_df, test_df\n",
    "\n",
    "# Point to your CASIA-B silhouette folder\n",
    "data_root = r\"D:\\vit study\\Machine Learning\\Gait\\CASIA - B\\CASIA - B\\GaitDatasetB-silh\\GaitDatasetB-silh\\GaitDatasetB-silh\"\n",
    "train_df, test_df = load_casia_b_090_df(data_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54e06bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Training  Testing\n",
      "condition                   \n",
      "nm              438      300\n",
      "bg              146      100\n",
      "cl              146      100\n"
     ]
    }
   ],
   "source": [
    "counts = pd.DataFrame({\n",
    "    'Training': train_df['condition'].value_counts(),\n",
    "    'Testing':  test_df['condition'].value_counts()\n",
    "}).fillna(0).astype(int)\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67cfe05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts.plot(kind='bar', figsize=(6,4))\n",
    "plt.title('Number of 090° Sequences per Condition')\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Sequence Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57b54995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': '001',\n",
       " 'condition': 'nm',\n",
       " 'sequence': 'nm-01',\n",
       " 'view': '090',\n",
       " 'path': 'D:\\\\vit study\\\\Machine Learning\\\\Gait\\\\CASIA - B\\\\CASIA - B\\\\GaitDatasetB-silh\\\\GaitDatasetB-silh\\\\GaitDatasetB-silh\\\\001\\\\nm-01\\\\090',\n",
       " 'num_frames': 56}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75bdb3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['001', '002', '003', '004', '006', '007', '008', '009', '010',\n",
       "       '011', '012', '013', '014', '015', '016', '017', '018', '019',\n",
       "       '020', '021', '022', '023', '024', '025', '026', '027', '028',\n",
       "       '029', '030', '031', '032', '033', '034', '035', '036', '037',\n",
       "       '038', '039', '040', '041', '042', '043', '044', '045', '046',\n",
       "       '047', '048', '049', '050', '051', '052', '053', '054', '055',\n",
       "       '056', '057', '058', '059', '060', '061', '062', '063', '064',\n",
       "       '065', '066', '067', '068', '069', '070', '071', '072', '073',\n",
       "       '074'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes=train_df[\"subject\"].unique()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d88b456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nm-01', 'nm-02', 'nm-03', 'nm-04', 'nm-05', 'nm-06', 'bg-01',\n",
       "       'bg-02', 'cl-01', 'cl-02'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"sequence\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48aac22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 86\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(os.listdir(ent['path'])) for ent in train_data]\n",
    "print(min(lengths), max(lengths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbc5c53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty training sequences: 0\n",
      "\n",
      "Empty testing sequences: 0\n"
     ]
    }
   ],
   "source": [
    "# List entries with zero frames\n",
    "empty_train = [e for e in train_data if e['num_frames'] <= 40]\n",
    "empty_test  = [e for e in test_data  if e['num_frames'] <= 40]\n",
    "\n",
    "print(f\"Empty training sequences: {len(empty_train)}\")\n",
    "for e in empty_train:\n",
    "    print(f\"Subject {e['subject']}, Condition {e['condition']}, Sequence {e['sequence']}, View {e['view']}\")\n",
    "\n",
    "print(f\"\\nEmpty testing sequences: {len(empty_test)}\")\n",
    "for e in empty_test:\n",
    "    print(f\"Subject {e['subject']}, Condition {e['condition']}, Sequence {e['sequence']}, View {e['view']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a0008b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sequences after filtering: 730\n",
      "Testing sequences after filtering: 500\n"
     ]
    }
   ],
   "source": [
    "MIN_SEQ_LEN = 40\n",
    "\n",
    "# Filter training data\n",
    "filtered_train = []\n",
    "for e in train_data:\n",
    "    if e['num_frames'] >= MIN_SEQ_LEN:\n",
    "        filtered_train.append(e)\n",
    "\n",
    "# Filter testing data\n",
    "filtered_test = []\n",
    "for e in test_data:\n",
    "    if e['num_frames'] >= MIN_SEQ_LEN:\n",
    "        filtered_test.append(e)\n",
    "\n",
    "# Update the original lists\n",
    "train_data = filtered_train\n",
    "test_data = filtered_test\n",
    "\n",
    "print(f\"Training sequences after filtering: {len(train_data)}\")\n",
    "print(f\"Testing sequences after filtering: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0f277c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "Subject: 006, Condition: nm, Sequence: nm-02, View: 090, Number of frames: 43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20a0d029810>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "rand_num = random.choice(range(len(train_data)))\n",
    "print(rand_num)\n",
    "sample=train_data[rand_num]\n",
    "sample_path=sample[\"path\"]\n",
    "sample_frames=os.listdir(sample_path)\n",
    "image=plt.imread(os.path.join(sample_path,random.choice(sample_frames)))\n",
    "print(f\"Subject: {sample['subject']}, Condition: {sample['condition']}, Sequence: {sample['sequence']}, View: {sample['view']}, Number of frames: {sample['num_frames']}\")  \n",
    "plt.imshow(image, cmap='prism_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1927e3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Pick the first training sequence\n",
    "rand_num = random.choice(range(len(train_data)))\n",
    "sample = train_data[rand_num]\n",
    "frame_files = sorted(f for f in os.listdir(sample['path']) if f.endswith('.png'))\n",
    "\n",
    "# Select three frames evenly spaced through the sequence\n",
    "indices = [0, len(frame_files)//2, len(frame_files)-1]\n",
    "selected = [frame_files[i] for i in indices]\n",
    "\n",
    "# Load and plot\n",
    "plt.figure(figsize=(9, 3))\n",
    "for i, fname in enumerate(selected):\n",
    "    img = plt.imread(os.path.join(sample['path'], fname))\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Frame {indices[i]+1}\")\n",
    "plt.suptitle(f\"Subject {sample['subject']}, {sample['condition']}, View {sample['view']}°\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11fae368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "IMG_HEIGHT = 120\n",
    "IMG_WIDTH  = 90\n",
    "\n",
    "def preprocess_frame(image_path):\n",
    "    \"\"\"\n",
    "    Reads an image file, decodes, resizes, and normalizes it.\n",
    "    \"\"\"\n",
    "    # Read & decode\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=1)            # grayscale\n",
    "    # Resize\n",
    "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    # Normalize to [0,1]\n",
    "    image = image / 255.0\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "979c08ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(120, 90, 1), dtype=float32, numpy=\n",
       "array([[[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]], shape=(120, 90, 1), dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_frame(os.path.join(sample_path, sample_frames[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dd95f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (730, 40, 120, 90, 1)\n",
      "Train labels shape: (730,)\n",
      "Test data shape: (500, 40, 120, 90, 1)\n",
      "Test labels shape: (500,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_HEIGHT = 120\n",
    "IMG_WIDTH  = 90\n",
    "SEQ_LEN    = 40\n",
    "\n",
    "def preprocess_frame(path):\n",
    "    # Read & decode\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    # Resize & normalize\n",
    "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    image = image / 255.0\n",
    "    return image.numpy()  # convert to NumPy\n",
    "\n",
    "def build_dataset(entries):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for ent in entries:\n",
    "        # Get sorted frame file names\n",
    "        files = sorted([f for f in os.listdir(ent['path']) if f.endswith('.png')])\n",
    "        # Truncate or pad to SEQ_LEN\n",
    "        files = files[:SEQ_LEN]\n",
    "        while len(files) < SEQ_LEN:\n",
    "            files.append(files[-1])\n",
    "        # Preprocess frames\n",
    "        seq = []\n",
    "        for fname in files:\n",
    "            img_path = os.path.join(ent['path'], fname)\n",
    "            img = preprocess_frame(img_path)\n",
    "            seq.append(img)\n",
    "        seq_array = np.stack(seq, axis=0)  # (SEQ_LEN, H, W, 1)\n",
    "        X_list.append(seq_array)\n",
    "        y_list.append(int(ent['subject']) - 1)  # zero-based label\n",
    "\n",
    "    # Stack all sequences\n",
    "    X = np.stack(X_list, axis=0)  # (N, SEQ_LEN, H, W, 1)\n",
    "    y = np.array(y_list, dtype=np.int32)\n",
    "    return X, y\n",
    "\n",
    "# Build datasets\n",
    "X_train, y_train = build_dataset(train_data)\n",
    "X_test,  y_test  = build_dataset(test_data)\n",
    "\n",
    "print(\"Train data shape:\", X_train.shape)\n",
    "print(\"Train labels shape:\", y_train.shape)\n",
    "print(\"Test data shape:\", X_test.shape)\n",
    "print(\"Test labels shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "260cafdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Training Set samples: 620\n",
      "Sequence length: 40\n",
      "Image size: 120 x 90\n",
      "Unique subjects in New Training Set: 73\n",
      "Label range: 0 to 73\n",
      "Sequences per subject in New Training Set: {np.int32(0): np.int64(9), np.int32(1): np.int64(8), np.int32(2): np.int64(8), np.int32(3): np.int64(8), np.int32(5): np.int64(9), np.int32(6): np.int64(9), np.int32(7): np.int64(8), np.int32(8): np.int64(9), np.int32(9): np.int64(8), np.int32(10): np.int64(9), np.int32(11): np.int64(9), np.int32(12): np.int64(8), np.int32(13): np.int64(9), np.int32(14): np.int64(9), np.int32(15): np.int64(8), np.int32(16): np.int64(8), np.int32(17): np.int64(9), np.int32(18): np.int64(8), np.int32(19): np.int64(9), np.int32(20): np.int64(9), np.int32(21): np.int64(8), np.int32(22): np.int64(8), np.int32(23): np.int64(9), np.int32(24): np.int64(8), np.int32(25): np.int64(8), np.int32(26): np.int64(9), np.int32(27): np.int64(8), np.int32(28): np.int64(8), np.int32(29): np.int64(9), np.int32(30): np.int64(8), np.int32(31): np.int64(9), np.int32(32): np.int64(9), np.int32(33): np.int64(8), np.int32(34): np.int64(9), np.int32(35): np.int64(9), np.int32(36): np.int64(9), np.int32(37): np.int64(8), np.int32(38): np.int64(8), np.int32(39): np.int64(8), np.int32(40): np.int64(9), np.int32(41): np.int64(9), np.int32(42): np.int64(8), np.int32(43): np.int64(9), np.int32(44): np.int64(8), np.int32(45): np.int64(9), np.int32(46): np.int64(9), np.int32(47): np.int64(8), np.int32(48): np.int64(9), np.int32(49): np.int64(8), np.int32(50): np.int64(9), np.int32(51): np.int64(9), np.int32(52): np.int64(8), np.int32(53): np.int64(8), np.int32(54): np.int64(8), np.int32(55): np.int64(8), np.int32(56): np.int64(9), np.int32(57): np.int64(9), np.int32(58): np.int64(9), np.int32(59): np.int64(8), np.int32(60): np.int64(9), np.int32(61): np.int64(8), np.int32(62): np.int64(9), np.int32(63): np.int64(8), np.int32(64): np.int64(9), np.int32(65): np.int64(8), np.int32(66): np.int64(9), np.int32(67): np.int64(8), np.int32(68): np.int64(8), np.int32(69): np.int64(8), np.int32(70): np.int64(8), np.int32(71): np.int64(9), np.int32(72): np.int64(8), np.int32(73): np.int64(9)}\n",
      "Validation Set samples: 110\n",
      "Sequence length: 40\n",
      "Image size: 120 x 90\n",
      "Unique subjects in Validation Set: 73\n",
      "Label range: 0 to 73\n",
      "Sequences per subject in Validation Set: {np.int32(0): np.int64(1), np.int32(1): np.int64(2), np.int32(2): np.int64(2), np.int32(3): np.int64(2), np.int32(5): np.int64(1), np.int32(6): np.int64(1), np.int32(7): np.int64(2), np.int32(8): np.int64(1), np.int32(9): np.int64(2), np.int32(10): np.int64(1), np.int32(11): np.int64(1), np.int32(12): np.int64(2), np.int32(13): np.int64(1), np.int32(14): np.int64(1), np.int32(15): np.int64(2), np.int32(16): np.int64(2), np.int32(17): np.int64(1), np.int32(18): np.int64(2), np.int32(19): np.int64(1), np.int32(20): np.int64(1), np.int32(21): np.int64(2), np.int32(22): np.int64(2), np.int32(23): np.int64(1), np.int32(24): np.int64(2), np.int32(25): np.int64(2), np.int32(26): np.int64(1), np.int32(27): np.int64(2), np.int32(28): np.int64(2), np.int32(29): np.int64(1), np.int32(30): np.int64(2), np.int32(31): np.int64(1), np.int32(32): np.int64(1), np.int32(33): np.int64(2), np.int32(34): np.int64(1), np.int32(35): np.int64(1), np.int32(36): np.int64(1), np.int32(37): np.int64(2), np.int32(38): np.int64(2), np.int32(39): np.int64(2), np.int32(40): np.int64(1), np.int32(41): np.int64(1), np.int32(42): np.int64(2), np.int32(43): np.int64(1), np.int32(44): np.int64(2), np.int32(45): np.int64(1), np.int32(46): np.int64(1), np.int32(47): np.int64(2), np.int32(48): np.int64(1), np.int32(49): np.int64(2), np.int32(50): np.int64(1), np.int32(51): np.int64(1), np.int32(52): np.int64(2), np.int32(53): np.int64(2), np.int32(54): np.int64(2), np.int32(55): np.int64(2), np.int32(56): np.int64(1), np.int32(57): np.int64(1), np.int32(58): np.int64(1), np.int32(59): np.int64(2), np.int32(60): np.int64(1), np.int32(61): np.int64(2), np.int32(62): np.int64(1), np.int32(63): np.int64(2), np.int32(64): np.int64(1), np.int32(65): np.int64(2), np.int32(66): np.int64(1), np.int32(67): np.int64(2), np.int32(68): np.int64(2), np.int32(69): np.int64(2), np.int32(70): np.int64(2), np.int32(71): np.int64(1), np.int32(72): np.int64(2), np.int32(73): np.int64(1)}\n",
      "\n",
      "NUM_CLASSES for model: 73\n",
      "All labels range: 0 to 73\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# RECOMMENDED: Use proper train-validation split with stratification\n",
    "# This ensures balanced representation and no unseen classes\n",
    "X_train_new, X_val, y_train_new, y_val = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=0.15,  # 15% for validation (about 100 samples from 730)\n",
    "    stratify=y_train,  # Maintains class distribution\n",
    "    random_state=42    # For reproducibility\n",
    ")\n",
    "\n",
    "# Report shapes and distributions\n",
    "def print_data_info(X, y, name=\"Dataset\"):\n",
    "    print(f\"{name} samples: {X.shape[0]}\")\n",
    "    print(f\"Sequence length: {X.shape[1]}\")\n",
    "    print(f\"Image size: {X.shape[2]} x {X.shape[3]}\")\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(f\"Unique subjects in {name}: {len(unique)}\")\n",
    "    print(f\"Label range: {unique.min()} to {unique.max()}\")\n",
    "    print(f\"Sequences per subject in {name}: {dict(zip(unique, counts))}\")\n",
    "\n",
    "print_data_info(X_train_new, y_train_new, \"New Training Set\")\n",
    "print_data_info(X_val, y_val, \"Validation Set\")\n",
    "\n",
    "# CRITICAL: Calculate NUM_CLASSES correctly\n",
    "all_labels = np.concatenate([y_train_new, y_val])\n",
    "NUM_CLASSES = len(np.unique(all_labels))\n",
    "print(f\"\\nNUM_CLASSES for model: {NUM_CLASSES}\")\n",
    "print(f\"All labels range: {all_labels.min()} to {all_labels.max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db111d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL LABEL VERIFICATION ===\n",
      "Training labels range: 0 to 73\n",
      "Validation labels range: 0 to 73\n",
      "Test labels range: 74 to 123\n",
      "NUM_CLASSES for model: 73\n",
      "Model expects labels: 0 to 72\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Validation labels exceed model capacity!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel expects labels: 0 to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUM_CLASSES\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Verify no issues\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m y_val\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m NUM_CLASSES, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation labels exceed model capacity!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m y_train_new\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m NUM_CLASSES, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining labels exceed model capacity!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ All labels are within model capacity\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Validation labels exceed model capacity!"
     ]
    }
   ],
   "source": [
    "# REMOVE the LabelEncoder code completely\n",
    "# Your labels are already properly encoded from the original data loading\n",
    "\n",
    "# After your validation split (Approach 2):\n",
    "print(\"=== FINAL LABEL VERIFICATION ===\")\n",
    "print(f\"Training labels range: {y_train_new.min()} to {y_train_new.max()}\")\n",
    "print(f\"Validation labels range: {y_val.min()} to {y_val.max()}\")\n",
    "print(f\"Test labels range: {y_test.min()} to {y_test.max()}\")\n",
    "\n",
    "# Calculate NUM_CLASSES based on what the model will actually see\n",
    "all_train_val_labels = np.concatenate([y_train_new, y_val])\n",
    "NUM_CLASSES = len(np.unique(all_train_val_labels))\n",
    "print(f\"NUM_CLASSES for model: {NUM_CLASSES}\")\n",
    "print(f\"Model expects labels: 0 to {NUM_CLASSES-1}\")\n",
    "\n",
    "# Verify no issues\n",
    "assert y_val.max() < NUM_CLASSES, \"Validation labels exceed model capacity!\"\n",
    "assert y_train_new.max() < NUM_CLASSES, \"Training labels exceed model capacity!\"\n",
    "print(\"✅ All labels are within model capacity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e2a9561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "--------------\n",
      "X_train_new shape: (620, 40, 120, 90, 1)\n",
      "y_train_new shape: (620,)\n",
      "Number of training samples: 620\n",
      "Sequence length: 40\n",
      "Image size: 120 x 90\n",
      "Number of unique subjects: 73\n",
      "Train subjects: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73]\n",
      "Sequences per subject in train set: [9 8 8 8 9 9 8 9 8 9 9 8 9 9 8 8 9 8 9 9 8 8 9 8 8 9 8 8 9 8 9 9 8 9 9 9 8\n",
      " 8 8 9 9 8 9 8 9 9 8 9 8 9 9 8 8 8 8 9 9 9 8 9 8 9 8 9 8 9 8 8 8 8 9 8 9]\n",
      "\n",
      "Test Data:\n",
      "----------\n",
      "X_test shape: (500, 40, 120, 90, 1)\n",
      "y_test shape: (500,)\n",
      "Number of test samples: 500\n",
      "Number of unique subjects in test set: 50\n",
      "Test subjects: [ 74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 114 115 116 117 118 119 120 121 122 123]\n",
      "Sequences per subject in test set: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training data info\n",
    "print(\"Training Data:\")\n",
    "print(\"--------------\")\n",
    "print(\"X_train_new shape:\", X_train_new.shape)  # (N, SEQ_LEN, IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "print(\"y_train_new shape:\", y_train_new.shape)\n",
    "print(f\"Number of training samples: {X_train_new.shape[0]}\")\n",
    "print(f\"Sequence length: {X_train_new.shape[1]}\")\n",
    "print(f\"Image size: {X_train_new.shape[2]} x {X_train_new.shape[3]}\")\n",
    "print(f\"Number of unique subjects: {len(np.unique(y_train_new))}\")\n",
    "\n",
    "unique_train, counts_train = np.unique(y_train_new, return_counts=True)\n",
    "print(\"Train subjects:\", unique_train)\n",
    "print(\"Sequences per subject in train set:\", counts_train)\n",
    "\n",
    "# Test data info\n",
    "print(\"\\nTest Data:\")\n",
    "print(\"----------\")\n",
    "print(\"X_test shape:\", X_test.shape)   # (N_test, SEQ_LEN, IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(f\"Number of test samples: {X_test.shape[0]}\")\n",
    "print(f\"Number of unique subjects in test set: {len(np.unique(y_test))}\")\n",
    "\n",
    "unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "print(\"Test subjects:\", unique_test)\n",
    "print(\"Sequences per subject in test set:\", counts_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ce5a709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pick a random sequence and show five evenly spaced frames from it\n",
    "i = random.randint(0, X_train.shape[0] - 1)\n",
    "seq = X_train[i]  # shape: (SEQ_LEN, IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "label = y_train[i]\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "indices = np.linspace(0, seq.shape[0] - 1, 5, dtype=int)  # 5 frames evenly spaced in sequence\n",
    "\n",
    "for idx, frame_num in enumerate(indices):\n",
    "    plt.subplot(1, 5, idx + 1)\n",
    "    plt.imshow(seq[frame_num, :, :, 0], cmap='gray')\n",
    "    plt.title(f\"Frame {frame_num + 1}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle(f\"Random Sequence - Subject {label}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "641f6e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets saved to casia_b_090_gait_data.npz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def save_gait_data(output_path='gait_data.npz'):\n",
    "    \"\"\"\n",
    "    Save training, validation, and test datasets into one .npz file.\n",
    "    Expects these variables to exist in the global namespace:\n",
    "      X_train_new, y_train_new, X_val, y_val, X_test, y_test\n",
    "    \"\"\"\n",
    "    np.savez(output_path,\n",
    "             X_train=X_train_new,\n",
    "             y_train=y_train_new,\n",
    "             X_val=X_val,\n",
    "             y_val=y_val,\n",
    "             X_test=X_test,\n",
    "             y_test=y_test)\n",
    "    print(f\"Datasets saved to {output_path}\")\n",
    "\n",
    "# Call this function once your datasets are prepared\n",
    "save_gait_data('casia_b_090_gait_data.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "437fab36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data shapes:\n",
      "X_train: (620, 40, 120, 90, 1)\n",
      "y_train: (620,)\n",
      "X_val: (110, 40, 120, 90, 1)\n",
      "y_val: (110,)\n",
      "X_test: (500, 40, 120, 90, 1)\n",
      "y_test: (500,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(r'D:\\vit study\\Machine Learning\\Gait\\casia_b_090_gait_data.npz')\n",
    "\n",
    "X_train_new = data['X_train']\n",
    "y_train_new = data['y_train']\n",
    "X_val = data['X_val']\n",
    "y_val = data['y_val']\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']\n",
    "\n",
    "print(\"Loaded data shapes:\")\n",
    "print(\"X_train:\", X_train_new.shape)\n",
    "print(\"y_train:\", y_train_new.shape)\n",
    "print(\"X_val:\", X_val.shape)\n",
    "print(\"y_val:\", y_val.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d18d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep your corrected NUM_CLASSES calculation\n",
    "NUM_CLASSES=74\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90ac50d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span>,    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37632</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">19,333,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,546</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m1\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m88\u001b[0m,    │           \u001b[38;5;34m320\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │ \u001b[38;5;34m32\u001b[0m)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m32\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m64\u001b[0m) │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m37632\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m19,333,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m)             │         \u001b[38;5;34m9,546\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,361,994</span> (73.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,361,994\u001b[0m (73.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,361,994</span> (73.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,361,994\u001b[0m (73.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "SEQ_LEN = 40\n",
    "IMG_HEIGHT = 120\n",
    "IMG_WIDTH = 90\n",
    "# This code should work as-is now:\n",
    "N, SEQ_LEN, H, W, C = X_train_new.shape\n",
    "X_train_frames = X_train_new.reshape(N * SEQ_LEN, H, W, C)\n",
    "y_train_frames = np.repeat(y_train_new, SEQ_LEN)\n",
    "\n",
    "N_val = X_val.shape[0]\n",
    "X_val_frames = X_val.reshape(N_val * SEQ_LEN, H, W, C)\n",
    "y_val_frames = np.repeat(y_val, SEQ_LEN)\n",
    "\n",
    "\n",
    "def build_cnn_lstm_model():\n",
    "    input_layer = layers.Input(shape=(SEQ_LEN, IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "    \n",
    "    # TimeDistributed CNN for per-frame feature extraction\n",
    "    x = layers.TimeDistributed(layers.Conv2D(32, (3,3), activation='relu'))(input_layer)\n",
    "    x = layers.TimeDistributed(layers.MaxPooling2D((2,2)))(x)\n",
    "    x = layers.TimeDistributed(layers.Conv2D(64, (3,3), activation='relu'))(x)\n",
    "    x = layers.TimeDistributed(layers.MaxPooling2D((2,2)))(x)\n",
    "    x = layers.TimeDistributed(layers.Flatten())(x)\n",
    "    \n",
    "    # LSTM for sequence modeling\n",
    "    x = layers.LSTM(128)(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "model = build_cnn_lstm_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d97d2ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_CLASSES: 74\n",
      "Label range: 0 to 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_19             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,356,544</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,810</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_18 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m1\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_19             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │     \u001b[38;5;34m1,356,544\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m)             │         \u001b[38;5;34m4,810\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,361,354</span> (5.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,361,354\u001b[0m (5.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,361,354</span> (5.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,361,354\u001b[0m (5.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "\n",
    "SEQ_LEN = 40\n",
    "IMG_HEIGHT = 120\n",
    "IMG_WIDTH = 90\n",
    "# Calculate based on ALL subjects that will be used (training + validation)\n",
    "all_train_val_labels = np.concatenate([y_train_new, y_val])\n",
    "print(f\"NUM_CLASSES: {NUM_CLASSES}\")\n",
    "print(f\"Label range: {all_train_val_labels.min()} to {all_train_val_labels.max()}\")\n",
    "\n",
    "def build_simpl_cnn():\n",
    "    # Input for a single frame\n",
    "    frame_input = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "    x = layers.Conv2D(16, (3,3), activation='relu', padding='same')(frame_input)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    model = models.Model(inputs=frame_input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Frame feature extractor\n",
    "cnn_model = build_simpl_cnn()\n",
    "\n",
    "# Input for entire sequence of frames\n",
    "sequence_input = layers.Input(shape=(SEQ_LEN, IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "# Process each frame with same CNN (TimeDistributed)\n",
    "frame_features = layers.TimeDistributed(cnn_model)(sequence_input)\n",
    "# Average frame features over time\n",
    "avg_features = layers.GlobalAveragePooling1D()(frame_features)\n",
    "# Final prediction\n",
    "output = layers.Dense(NUM_CLASSES, activation='softmax')(avg_features)\n",
    "\n",
    "model = models.Model(inputs=sequence_input, outputs=output)\n",
    "# Rebuild or modify model output layer accordingly\n",
    "model.layers[-1] = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bc9ee9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_new, y_train_new,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4caa48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training frames shape: (24800, 120, 90, 1)\n",
      "Validation frames shape: (4400, 120, 90, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "N, SEQ_LEN, H, W, C = X_train_new.shape\n",
    "\n",
    "# Flatten training sequences to frames\n",
    "X_train_frames = X_train_new.reshape(N * SEQ_LEN, H, W, C)\n",
    "y_train_frames = np.repeat(y_train_new, SEQ_LEN)\n",
    "\n",
    "# Flatten validation sequences to frames\n",
    "N_val = X_val.shape[0]\n",
    "X_val_frames = X_val.reshape(N_val * SEQ_LEN, H, W, C)\n",
    "y_val_frames = np.repeat(y_val, SEQ_LEN)\n",
    "\n",
    "print(\"Training frames shape:\", X_train_frames.shape)\n",
    "print(\"Validation frames shape:\", X_val_frames.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "96a2fb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"functional_14\" is incompatible with the layer: expected shape=(None, 40, 120, 90, 1), found shape=(32, 120, 90)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_frames\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\layers\\input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"functional_14\" is incompatible with the layer: expected shape=(None, 40, 120, 90, 1), found shape=(32, 120, 90)"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_frames, y_train_frames,\n",
    "    validation_data=(X_val_frames, y_val_frames),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad2e3b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built with 74 output classes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21120</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,351,744</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,810</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21120\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m1,351,744\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m)             │         \u001b[38;5;34m4,810\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,361,354</span> (5.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,361,354\u001b[0m (5.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,361,354</span> (5.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,361,354\u001b[0m (5.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "IMG_HEIGHT = 120\n",
    "IMG_WIDTH = 90\n",
    "NUM_CLASSES=74\n",
    "# NUM_CLASSES is now 74 (from your corrected calculation)\n",
    "\n",
    "def build_simple_cnn():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
    "        layers.Conv2D(16, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax')  # Now 74 instead of 63!\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_simple_cnn()\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(f\"Model built with {NUM_CLASSES} output classes\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da658428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current NUM_CLASSES: 74\n",
      "Should be: 74\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current NUM_CLASSES: {NUM_CLASSES}\")\n",
    "print(f\"Should be: 74\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7353b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PRE-TRAINING VERIFICATION ===\n",
      "Training frames shape: (24800, 120, 90, 1)\n",
      "Training labels range: 0 to 73\n",
      "Validation frames shape: (4400, 120, 90, 1)\n",
      "Validation labels range: 0 to 73\n",
      "Model expects labels: 0 to 73\n",
      "✅ All checks passed - ready for training!\n",
      "Epoch 1/10\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 83ms/step - accuracy: 0.3937 - loss: 2.2485 - val_accuracy: 0.4884 - val_loss: 1.7747\n",
      "Epoch 2/10\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 67ms/step - accuracy: 0.7710 - loss: 0.7258 - val_accuracy: 0.5952 - val_loss: 1.5234\n",
      "Epoch 3/10\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 69ms/step - accuracy: 0.8772 - loss: 0.3728 - val_accuracy: 0.6427 - val_loss: 1.5228\n",
      "Epoch 4/10\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 60ms/step - accuracy: 0.9276 - loss: 0.2158 - val_accuracy: 0.6430 - val_loss: 1.7269\n",
      "Epoch 5/10\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 51ms/step - accuracy: 0.9502 - loss: 0.1504 - val_accuracy: 0.6730 - val_loss: 1.6484\n",
      "Epoch 6/10\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 52ms/step - accuracy: 0.9607 - loss: 0.1149 - val_accuracy: 0.6777 - val_loss: 1.8075\n",
      "Epoch 7/10\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 65ms/step - accuracy: 0.9680 - loss: 0.0981 - val_accuracy: 0.6775 - val_loss: 1.8650\n",
      "Epoch 8/10\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 70ms/step - accuracy: 0.9742 - loss: 0.0804 - val_accuracy: 0.6870 - val_loss: 1.8054\n",
      "Epoch 9/10\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 57ms/step - accuracy: 0.9767 - loss: 0.0731 - val_accuracy: 0.6843 - val_loss: 1.9000\n",
      "Epoch 10/10\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 61ms/step - accuracy: 0.9808 - loss: 0.0576 - val_accuracy: 0.6911 - val_loss: 2.0263\n"
     ]
    }
   ],
   "source": [
    "# Add verification before training\n",
    "print(\"=== PRE-TRAINING VERIFICATION ===\")\n",
    "print(f\"Training frames shape: {X_train_frames.shape}\")\n",
    "print(f\"Training labels range: {y_train_frames.min()} to {y_train_frames.max()}\")\n",
    "print(f\"Validation frames shape: {X_val_frames.shape}\")\n",
    "print(f\"Validation labels range: {y_val_frames.min()} to {y_val_frames.max()}\")\n",
    "print(f\"Model expects labels: 0 to {NUM_CLASSES-1}\")\n",
    "print(f\"✅ All checks passed - ready for training!\")\n",
    "\n",
    "# Your original training code should now work\n",
    "history = model.fit(\n",
    "    X_train_frames, y_train_frames,\n",
    "    validation_data=(X_val_frames, y_val_frames),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b557389e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels range: 0 to 73\n",
      "Validation labels range: 0 to 73\n",
      "Test labels range: 74 to 123\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train labels range: {y_train_new.min()} to {y_train_new.max()}\")\n",
    "print(f\"Validation labels range: {y_val.min()} to {y_val.max()}\")\n",
    "print(f\"Test labels range: {y_test.min()} to {y_test.max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fb5848f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m test_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(y_test_known, X_test_known\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📊 Test Accuracy on known classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Mask to select only known classes in test set (0 to 73)\n",
    "known_test_mask = (y_test >= 0) & (y_test <= 73)\n",
    "\n",
    "X_test_known = X_test[known_test_mask]\n",
    "y_test_known = y_test[known_test_mask]\n",
    "\n",
    "# Prepare frames and labels for evaluation\n",
    "test_frames = X_test_known.reshape(-1, IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "test_labels = np.repeat(y_test_known, X_test_known.shape[1])\n",
    "\n",
    "# Evaluate\n",
    "test_accuracy = model.evaluate(test_frames, test_labels, verbose=0)[1]\n",
    "print(f\"📊 Test Accuracy on known classes: {test_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c79ae6ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\asyncio\\base_events.py\", line 595, in run_forever\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\asyncio\\base_events.py\", line 1881, in _run_once\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n\n  File \"C:\\Users\\ankit\\AppData\\Local\\Temp\\ipykernel_16608\\754371133.py\", line 11, in <module>\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 401, in fit\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 489, in evaluate\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 220, in function\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 114, in one_step_on_data\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 93, in test_step\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 383, in _compute_loss\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 351, in compute_loss\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 690, in __call__\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 699, in call\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\losses\\loss.py\", line 67, in __call__\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\losses\\losses.py\", line 33, in call\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\losses\\losses.py\", line 2330, in sparse_categorical_crossentropy\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\ops\\nn.py\", line 2008, in sparse_categorical_crossentropy\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 753, in sparse_categorical_crossentropy\n\nReceived a label value of 74 which is outside the valid range of [0, 74).  Label values: 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_multi_step_on_iterator_14084]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m test_frames \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, IMG_HEIGHT, IMG_WIDTH, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m test_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(y_test, X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📊 Final Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Detailed test analysis\u001b[39;00m\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\asyncio\\base_events.py\", line 595, in run_forever\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\asyncio\\base_events.py\", line 1881, in _run_once\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n\n  File \"C:\\Users\\ankit\\AppData\\Local\\Temp\\ipykernel_16608\\754371133.py\", line 11, in <module>\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 401, in fit\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 489, in evaluate\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 220, in function\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 114, in one_step_on_data\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 93, in test_step\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 383, in _compute_loss\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 351, in compute_loss\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 690, in __call__\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 699, in call\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\losses\\loss.py\", line 67, in __call__\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\losses\\losses.py\", line 33, in call\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\losses\\losses.py\", line 2330, in sparse_categorical_crossentropy\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\ops\\nn.py\", line 2008, in sparse_categorical_crossentropy\n\n  File \"d:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 753, in sparse_categorical_crossentropy\n\nReceived a label value of 74 which is outside the valid range of [0, 74).  Label values: 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_multi_step_on_iterator_14084]"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set (do this ONLY once after training)\n",
    "test_frames = X_test.reshape(-1, IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "test_labels = np.repeat(y_test, X_test.shape[1])\n",
    "\n",
    "test_accuracy = model.evaluate(test_frames, test_labels, verbose=0)[1]\n",
    "print(f\"📊 Final Test Accuracy: {test_accuracy:.2%}\")\n",
    "\n",
    "# Detailed test analysis\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "test_predictions = model.predict(test_frames)\n",
    "test_pred_classes = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "print(\"📈 Test Set Classification Report:\")\n",
    "print(classification_report(test_labels, test_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16269e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Open Set Recognition model built!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21120</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,406,976</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ classification_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,018</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21120\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_layer (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m5,406,976\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ classification_layer (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m)             │        \u001b[38;5;34m19,018\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,519,562</span> (21.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,519,562\u001b[0m (21.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,519,114</span> (21.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,519,114\u001b[0m (21.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import weibull_min\n",
    "import pickle\n",
    "\n",
    "def build_open_set_gait_model():\n",
    "    \"\"\"\n",
    "    Build model with embedding layer for open set recognition\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
    "        \n",
    "        # Feature extraction layers\n",
    "        layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        \n",
    "        # Embedding layer (important for open set recognition)\n",
    "        layers.Dense(256, activation='relu', name='embedding_layer'),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        # Classification layer\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax', name='classification_layer')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build and compile the model\n",
    "model = build_open_set_gait_model()\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"✅ Open Set Recognition model built!\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11210930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 448ms/step - accuracy: 0.0135 - loss: 4.4206 - val_accuracy: 0.0102 - val_loss: 4.3060\n",
      "Epoch 2/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 428ms/step - accuracy: 0.0129 - loss: 4.2960 - val_accuracy: 0.0091 - val_loss: 4.3076\n",
      "Epoch 3/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 430ms/step - accuracy: 0.0112 - loss: 4.2930 - val_accuracy: 0.0091 - val_loss: 4.3099\n",
      "Epoch 4/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 431ms/step - accuracy: 0.0121 - loss: 4.2917 - val_accuracy: 0.0091 - val_loss: 4.3112\n",
      "Epoch 5/50\n",
      "\u001b[1m 58/775\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:09\u001b[0m 432ms/step - accuracy: 0.0120 - loss: 4.2880"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model normally on known classes (0-73)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_frames\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Model training completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(begin_step)\n\u001b[1;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(end_step, logs)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    219\u001b[0m     ):\n\u001b[1;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32md:\\vit study\\Machine Learning\\GEN AI Model\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model normally on known classes (0-73)\n",
    "history = model.fit(\n",
    "    X_train_frames, y_train_frames,\n",
    "    validation_data=(X_val_frames, y_val_frames),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"✅ Model training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46c7333",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenSetRecognizer:\n",
    "    def __init__(self, model, num_classes):\n",
    "        self.model = model\n",
    "        self.num_classes = num_classes\n",
    "        self.class_means = {}\n",
    "        self.weibull_models = {}\n",
    "        self.confidence_threshold = 0.5  # Adjustable threshold\n",
    "        \n",
    "        # Create embedding model (without final classification layer)\n",
    "        self.embedding_model = models.Model(\n",
    "            inputs=model.input,\n",
    "            outputs=model.get_layer('embedding_layer').output\n",
    "        )\n",
    "    \n",
    "    def fit_weibull_models(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit Weibull distribution for each class using training data\n",
    "        \"\"\"\n",
    "        print(\"🔧 Fitting Weibull models for open set recognition...\")\n",
    "        \n",
    "        # Get embeddings for all training samples\n",
    "        train_embeddings = self.embedding_model.predict(X_train, verbose=0)\n",
    "        \n",
    "        for class_id in range(self.num_classes):\n",
    "            # Get embeddings for this specific class\n",
    "            class_mask = (y_train == class_id)\n",
    "            if not np.any(class_mask):\n",
    "                continue\n",
    "                \n",
    "            class_embeddings = train_embeddings[class_mask]\n",
    "            \n",
    "            # Compute class mean (centroid)\n",
    "            class_mean = np.mean(class_embeddings, axis=0)\n",
    "            self.class_means[class_id] = class_mean\n",
    "            \n",
    "            # Calculate distances from centroid\n",
    "            distances = np.linalg.norm(class_embeddings - class_mean, axis=1)\n",
    "            \n",
    "            # Fit Weibull distribution on distances\n",
    "            if len(distances) > 1:  # Need at least 2 points\n",
    "                # Take the largest distances (most extreme samples)\n",
    "                sorted_distances = np.sort(distances)\n",
    "                extreme_distances = sorted_distances[-max(1, len(distances)//4):]  # Top 25%\n",
    "                \n",
    "                # Fit Weibull distribution\n",
    "                try:\n",
    "                    weibull_params = weibull_min.fit(extreme_distances, floc=0)\n",
    "                    self.weibull_models[class_id] = weibull_params\n",
    "                except:\n",
    "                    # Fallback: use mean and std for simple thresholding\n",
    "                    self.weibull_models[class_id] = (np.mean(distances), np.std(distances))\n",
    "                    \n",
    "            print(f\"Class {class_id}: {len(class_embeddings)} samples processed\")\n",
    "        \n",
    "        print(\"✅ Weibull models fitted for all classes!\")\n",
    "    \n",
    "    def predict_with_unknown(self, X_test, return_probabilities=False):\n",
    "        \"\"\"\n",
    "        Predict with unknown class detection\n",
    "        Returns: predictions array where unknown samples are labeled as 'unknown'\n",
    "        \"\"\"\n",
    "        # Get regular predictions and probabilities\n",
    "        predictions_prob = self.model.predict(X_test, verbose=0)\n",
    "        predictions_class = np.argmax(predictions_prob, axis=1)\n",
    "        max_probabilities = np.max(predictions_prob, axis=1)\n",
    "        \n",
    "        # Get embeddings\n",
    "        test_embeddings = self.embedding_model.predict(X_test, verbose=0)\n",
    "        \n",
    "        final_predictions = []\n",
    "        confidence_scores = []\n",
    "        \n",
    "        for i, (pred_class, max_prob, embedding) in enumerate(zip(predictions_class, max_probabilities, test_embeddings)):\n",
    "            \n",
    "            # Method 1: Confidence thresholding\n",
    "            confidence_score = max_prob\n",
    "            \n",
    "            # Method 2: Distance-based detection (if Weibull model exists)\n",
    "            distance_score = 1.0  # Default to accepting\n",
    "            \n",
    "            if pred_class in self.class_means and pred_class in self.weibull_models:\n",
    "                # Calculate distance to predicted class centroid\n",
    "                distance_to_centroid = np.linalg.norm(embedding - self.class_means[pred_class])\n",
    "                \n",
    "                # Check if distance is reasonable according to Weibull model\n",
    "                weibull_params = self.weibull_models[pred_class]\n",
    "                \n",
    "                if len(weibull_params) == 3:  # Proper Weibull parameters\n",
    "                    # Calculate probability of this distance under Weibull distribution\n",
    "                    distance_prob = weibull_min.cdf(distance_to_centroid, *weibull_params)\n",
    "                    distance_score = distance_prob\n",
    "                else:  # Fallback method\n",
    "                    mean_dist, std_dist = weibull_params\n",
    "                    # Simple z-score based detection\n",
    "                    z_score = (distance_to_centroid - mean_dist) / (std_dist + 1e-6)\n",
    "                    distance_score = max(0, 1 - abs(z_score) / 3)  # Normalize to 0-1\n",
    "            \n",
    "            # Combined confidence score\n",
    "            combined_confidence = (confidence_score + distance_score) / 2\n",
    "            confidence_scores.append(combined_confidence)\n",
    "            \n",
    "            # Decision: known vs unknown\n",
    "            if combined_confidence > self.confidence_threshold:\n",
    "                final_predictions.append(pred_class)  # Return actual class label\n",
    "            else:\n",
    "                final_predictions.append('unknown')  # Return 'unknown'\n",
    "        \n",
    "        if return_probabilities:\n",
    "            return final_predictions, confidence_scores\n",
    "        return final_predictions\n",
    "    \n",
    "    def set_threshold(self, threshold):\n",
    "        \"\"\"Set the confidence threshold for unknown detection\"\"\"\n",
    "        self.confidence_threshold = threshold\n",
    "        print(f\"🎯 Confidence threshold set to: {threshold}\")\n",
    "    \n",
    "    def save_models(self, filepath):\n",
    "        \"\"\"Save the Weibull models and class means\"\"\"\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'class_means': self.class_means,\n",
    "                'weibull_models': self.weibull_models,\n",
    "                'threshold': self.confidence_threshold\n",
    "            }, f)\n",
    "        print(f\"💾 OpenSet models saved to {filepath}\")\n",
    "    \n",
    "    def load_models(self, filepath):\n",
    "        \"\"\"Load the Weibull models and class means\"\"\"\n",
    "        with open(filepath, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            self.class_means = data['class_means']\n",
    "            self.weibull_models = data['weibull_models']\n",
    "            self.confidence_threshold = data['threshold']\n",
    "        print(f\"📂 OpenSet models loaded from {filepath}\")\n",
    "\n",
    "# Initialize the open set recognizer\n",
    "open_set_recognizer = OpenSetRecognizer(model, NUM_CLASSES)\n",
    "\n",
    "# Fit Weibull models on training data\n",
    "open_set_recognizer.fit_weibull_models(X_train_frames, y_train_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb7513e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
